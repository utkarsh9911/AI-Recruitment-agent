{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b086dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fa36fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import io\n",
    "import google.generativeai as genaiI\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aedcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\AI-Recruitment-agent\\datascienceresume32 - Google Docs.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23703b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loder = PyPDFLoader(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c660501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loder.load()\n",
    "\n",
    "# print(documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91f5af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEYY = os.getenv(\"GEMINI_API\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da0208ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke('hii')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "440f7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "texts = [doc.page_content for doc in chunks]  # Extract text from Document objects\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be38b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23132235",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c0be5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "74d51ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a51b8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": 'What is my fathers name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e62240b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the provided text doesn't contain any information about your father's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "39cf8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "●  Data Science Certification  -  Coursera  November 2023 \n",
      " ●  Earned Badge of Python and SQL  –  HackerRank  January 2024 \n",
      " ●  Five Star Python Coder -  HackerRank  May 2024 \n",
      " ADDITIONAL INFORMA TION \n",
      " ●  Location :  Delhi \n",
      " ●  Availability :  Immediate Joiner\n"
     ]
    }
   ],
   "source": [
    "print(response['context'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d9fa2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_to_analyze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Python: 9/10\n",
      "  Reasoning: \n",
      "  Score for Java: 0/10\n",
      "  Reasoning: \n",
      "  Score for React: 0/10\n",
      "  Reasoning: \n",
      "  Score for PostgreSQL: 0/10\n",
      "  Reasoning: \n",
      "  Score for Cloud Computing (AWS/Azure/GCP): 0/10\n",
      "  Reasoning: \n",
      "  Score for Leadership: 0/10\n",
      "  Reasoning: \n",
      "  Score for Project Management: 1/10\n",
      "  Reasoning: Rating: 0\n",
      "  Score for Machine Learning: 10/10\n",
      "  Reasoning: \n"
     ]
    }
   ],
   "source": [
    "skill_scores = []\n",
    "for skill in skills_to_analyze:\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1) if match else 0)\n",
    "    reasoning_parts = response['answer'].split('\\n', 1)\n",
    "    if len(reasoning_parts) > 1:\n",
    "            \n",
    "            reasoning = reasoning_parts[1].strip()\n",
    "    else:\n",
    "            reasoning = response['answer'].strip()\n",
    "    # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "    final_score = min(score, 10)\n",
    "    skill_scores.append(final_score)\n",
    "    print(f\"  Score for {skill}: {final_score}/10\")\n",
    "    print(f\"  Reasoning: {reasoning}\")\n",
    "# Overall score calculation\n",
    "    \n",
    "# overall_score = sum(skill_scores)\n",
    "# n = len(skill_scores)\n",
    "# print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "# find overll score\n",
    "print(skill_scores)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb324213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Python: 9/10\n",
      "  Reasoning: The candidate explicitly mentions Python under \"Programming Languages\" in the \"TECHNICAL SKILLS\" section and lists multiple projects and achievements highlighting their proficiency with the language (e.g., \"Five Star Python Coder\", developed multiple projects).\n",
      "  Score for Java: 0/10\n",
      "  Reasoning: Java is not mentioned.\n",
      "  Score for React: 0/10\n",
      "  Reasoning: The candidate does not mention React anywhere in the provided context.\n",
      "  Score for PostgreSQL: 0/10\n",
      "  Reasoning: The candidate doesn't mention PostgreSQL anywhere in the provided context.\n",
      "  Score for Cloud Computing (AWS/Azure/GCP): 0/10\n",
      "  Reasoning: There is no mention of Cloud Computing skills (AWS/Azure/GCP) in the provided context.\n",
      "  Score for Leadership: 0/10\n",
      "  Reasoning: There is no mention of Leadership in the provided context.\n",
      "  Score for Project Management: 1/10\n",
      "  Reasoning: Reasoning: The candidate doesn't explicitly mention or showcase proficiency in project management skills within the provided context.\n",
      "  Score for Machine Learning: 10/10\n",
      "  Reasoning: The candidate explicitly lists Machine Learning as a Data Science skill, describes machine learning projects with accuracy percentages, and details the tools and libraries used. Their work experience also includes machine learning models.\n",
      "Overall Score: 20/80\n"
     ]
    }
   ],
   "source": [
    "# final code\n",
    "skill_scores = []\n",
    "for skill in skills_to_analyze:\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1) if match else 0)\n",
    "    reasoning_parts = response['answer']\n",
    "    reasining_lines = [line.strip() for line in reasoning_parts.split('\\n') if line.strip()]\n",
    "    \n",
    "    raw_reasoning = ' '.join(reasining_lines)\n",
    "   \n",
    "    final_resoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "    # if len(reasoning_parts) > 1:\n",
    "            \n",
    "    #         reasoning = reasoning_parts[1].strip()\n",
    "    # else:\n",
    "    #         reasoning = response['answer'].strip()\n",
    "    # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "    final_score = min(score, 10)\n",
    "    skill_scores.append(final_score)\n",
    "    print(f\"  Score for {skill}: {final_score}/10\")\n",
    "    print(f\"  Reasoning: {final_resoning}\")\n",
    "# Overall score calculation\n",
    "    \n",
    "overall_score = sum(skill_scores)\n",
    "n = len(skill_scores)\n",
    "print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b8f1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='9'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match = re.search(r'(\\d+)', response['answer'])\n",
    "print(match)\n",
    "score = int(match.group(1) if match else 0)\n",
    "# print(score)\n",
    "reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "print(reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7412d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 - The candidate explicitly lists \"Machine Learning\" under the \"Data Science\" technical skills section, and provides project examples (Gemstone Price Predictor, Stock Price Forecasting using LSTM, MaternAI) that heavily rely on Machine Learning techniques. The experience at Infosys and Zidio Development also showcases the practical application of machine learning models.\n"
     ]
    }
   ],
   "source": [
    "resoning_parts = response['answer'].strip().split('\\n', 1)\n",
    "if len(resoning_parts) > 1:\n",
    "    reasoning = resoning_parts[1].strip()\n",
    "else:   \n",
    "    reasoning = response['answer'].strip()\n",
    "\n",
    "print(reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5be75290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Machine Learning: 9/10\n",
      "  Reasoning: 9 - The candidate explicitly lists \"Machine Learning\" under the \"Data Science\" technical skills section, and provides project examples (Gemstone Price Predictor, Stock Price Forecasting using LSTM, MaternAI) that heavily rely on Machine Learning techniques. The experience at Infosys and Zidio Development also showcases the practical application of machine learning models.\n"
     ]
    }
   ],
   "source": [
    "# Ensure score is within 0-10 range\n",
    "final_score = min(max(score, 0), 10)\n",
    "print(f\"  Score for {skill}: {final_score}/10\")\n",
    "print(f\"  Reasoning: {reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6951997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import panda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
