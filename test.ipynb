{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b086dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa36fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UTKARSH\\.conda\\envs\\aiagent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import io\n",
    "import google.generativeai as genaiI\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\AI-Recruitment-agent\\datascienceresume32 - Google Docs.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23703b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loder = PyPDFLoader(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c660501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loder.load()\n",
    "\n",
    "# print(documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f5af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEYY = os.getenv(\"GEMINI_API\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da0208ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke('hii')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "440f7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum size of each chunk\n",
    "    chunk_overlap=200,    # Overlap between chunks to maintain context\n",
    "    length_function=len  # Function to measure chunk length\n",
    "    \n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "texts = [doc.page_content for doc in chunks]  # Extract text from Document objects\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be38b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23132235",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0be5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d51ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "ra_chain = create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a51b8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ra_chain.invoke({\"input\": 'What is my fathers name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e62240b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but this document does not contain information about the father's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cf8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "●  Data Science Certification  -  Coursera  November 2023 \n",
      " ●  Earned Badge of Python and SQL  –  HackerRank  January 2024 \n",
      " ●  Five Star Python Coder -  HackerRank  May 2024 \n",
      " ADDITIONAL INFORMA TION \n",
      " ●  Location :  Delhi \n",
      " ●  Availability :  Immediate Joiner\n"
     ]
    }
   ],
   "source": [
    "print(response['context'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fa2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_to_analyze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c81960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_scores = []\n",
    "# for skill in skills_to_analyze:\n",
    "#     query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "#     response = retrieval_chain.invoke({\"input\": query})\n",
    "#     match = re.search(r'(\\d+)', response['answer'])\n",
    "#     score = int(match.group(1) if match else 0)\n",
    "#     reasoning_parts = response['answer'].split('\\n', 1)\n",
    "#     if len(reasoning_parts) > 1:\n",
    "            \n",
    "#             reasoning = reasoning_parts[1].strip()\n",
    "#     else:\n",
    "#             reasoning = response['answer'].strip()\n",
    "#     # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "#     final_score = min(score, 10)\n",
    "#     skill_scores.append(final_score)\n",
    "#     print(f\"  Score for {skill}: {final_score}/10\")\n",
    "#     print(f\"  Reasoning: {reasoning}\")\n",
    "# # Overall score calculation\n",
    "    \n",
    "# # overall_score = sum(skill_scores)\n",
    "# # n = len(skill_scores)\n",
    "# # print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "# # find overll score\n",
    "# print(skill_scores)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb324213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Python: 10/10\n",
      "  Reasoning: The candidate explicitly lists Python under \"Programming Languages,\" earned a \"Five Star Python Coder\" badge, and has multiple projects and experiences demonstrating Python skills.\n",
      "  Score for Java: 0/10\n",
      "  Reasoning: The document does not mention Java at all.\n",
      "  Score for React: 0/10\n",
      "  Reasoning: React is not mentioned in the provided context.\n",
      "  Score for PostgreSQL: 0/10\n",
      "  Reasoning: The candidate does not mention PostgreSQL.\n",
      "  Score for Cloud Computing (AWS/Azure/GCP): 0/10\n",
      "  Reasoning: The candidate does not mention any Cloud Computing skills (AWS/Azure/GCP) in the provided context.\n",
      "  Score for Leadership: 0/10\n",
      "  Reasoning: The candidate does not mention leadership skills or experience in the provided context.\n",
      "  Score for Project Management: 0/10\n",
      "  Reasoning: The candidate does not mention proficiency in Project Management.\n",
      "  Score for Machine Learning: 10/10\n",
      "  Reasoning: /10. The candidate mentions Machine Learning under \"Technical Skills\", and implements Machine Learning in multiple projects and previous work experience.\n",
      "Overall Score: 20/80\n"
     ]
    }
   ],
   "source": [
    "# final code\n",
    "skill_scores = []\n",
    "for skill in skills_to_analyze:\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "    response = ra_chain.invoke({\"input\": query})\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1) if match else 0)\n",
    "    reasoning_parts = response['answer']\n",
    "    reasining_lines = [line.strip() for line in reasoning_parts.split('\\n') if line.strip()]\n",
    "    \n",
    "    raw_reasoning = ' '.join(reasining_lines)\n",
    "   \n",
    "    final_resoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "    # if len(reasoning_parts) > 1:\n",
    "            \n",
    "    #         reasoning = reasoning_parts[1].strip()\n",
    "    # else:\n",
    "    #         reasoning = response['answer'].strip()\n",
    "    # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "    final_score = min(score, 10)\n",
    "    skill_scores.append(final_score)\n",
    "    print(f\"  Score for {skill}: {final_score}/10\")\n",
    "    print(f\"  Reasoning: {final_resoning}\")\n",
    "# Overall score calculation\n",
    "    \n",
    "overall_score = sum(skill_scores)\n",
    "n = len(skill_scores)\n",
    "print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaknesses  = []\n",
    "improvement_suggestions = {}\n",
    "\n",
    "analysis_result = {\n",
    "    \"missing_skill\": [\"Mlops\", \"Devops\", 'GenerativeAI']\n",
    "}\n",
    "\n",
    "for skill in analysis_result.get('missing_skill', []):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "\n",
    "    For your analysis, consider:\n",
    "    1. What's missing from the resume regarding this skill?\n",
    "    2. How could it be improved with specific examples?\n",
    "    3. What specific action items would make this skill stand out?\n",
    "\n",
    "    Provide your response in this JSON format:\n",
    "    {{\n",
    "        \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "        \"improvement_suggestions\": [\n",
    "            \"Specific suggestion 1\",\n",
    "            \"Specific suggestion 2\",\n",
    "            \"Specific suggestion 3\"\n",
    "        ],\n",
    "        \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "    }}\n",
    "\n",
    "    Return only valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ra_chain.invoke({\"input\": prompt})\n",
    "    \n",
    "    # ✅ Extract string answer\n",
    "    raw_json = response['answer']\n",
    "\n",
    "    # ✅ Remove backticks and 'json' label\n",
    "    cleaned_json = re.sub(r'^```json|```$', '', raw_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        # ✅ Parse string into dictionary\n",
    "        weakness_data = json.loads(cleaned_json)\n",
    "\n",
    "        # ✅ Store in desired format\n",
    "        weakness_detail = {\n",
    "            \"skill\": skill,\n",
    "            \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "            \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "            \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "        }\n",
    "\n",
    "        weaknesses.append(weakness_detail)\n",
    "        improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed for skill {skill}: {e}\")\n",
    "        weaknesses.append({\n",
    "            \"skill\": skill,\n",
    "            \"detail\": raw_json[:200],  # fallback: first 200 characters\n",
    "            \n",
    "            \"example\": \"\"\n",
    "        })\n",
    "\n",
    "resume_weakness = weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "333c755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skill: Mlops\n",
      "❌ Weakness: The resume is weak in demonstrating proficiency in MLOps because it lacks any explicit mention of MLOps practices, tools, or experience with deploying and managing machine learning models in a production environment. While the resume highlights model building and accuracy, it doesn't showcase understanding of the complete ML lifecycle.\n",
      "📌 Example: Implemented CI/CD pipeline using GitHub Actions and Docker to automate model deployment for the Gemstone Price Predictor, reducing deployment time by 50%.\n",
      "✅ Suggestions:\n",
      "  - Include experience with model deployment tools like Docker, Kubernetes, AWS SageMaker, or similar.\n",
      "  - Mention any involvement in model monitoring, retraining, or version control processes.\n",
      "  - Specify if any CI/CD pipelines were used for model deployment.\n",
      "\n",
      "🔧 Skill: Devops\n",
      "❌ Weakness: The resume is weak in demonstrating proficiency in DevOps because it lacks any explicit mention or demonstration of skills, tools, or experiences related to DevOps practices like CI/CD, containerization, infrastructure as code, or automation. While the projects showcase data science skills, they don't illustrate how the models were deployed or managed in a production environment, which are key aspects of DevOps.\n",
      "📌 Example: Implemented CI/CD pipeline using Jenkins and Docker to automate the deployment of the sentiment analysis model, reducing deployment time by 50% and improving system uptime by 15%.\n",
      "✅ Suggestions:\n",
      "  - Include a section specifically listing DevOps skills and tools, such as Docker, Kubernetes, Jenkins, Ansible, Terraform, AWS CloudFormation, Azure DevOps, or similar.\n",
      "  - Describe any experience with automating deployment pipelines, infrastructure management, or monitoring and logging systems.\n",
      "  - Quantify the impact of any DevOps-related implementations, such as reduced deployment time or improved system uptime.\n",
      "\n",
      "🔧 Skill: GenerativeAI\n",
      "❌ Weakness: The resume lacks any explicit mention or demonstration of skills and experience in Generative AI. While NLP and chatbot development are related, they do not directly showcase proficiency in Generative AI models like GANs, diffusion models, or large language models used for content creation.\n",
      "📌 Example: Developed a generative model using GANs to create synthetic datasets for [application area], achieving a [quantifiable metric] improvement in downstream task performance.\n",
      "✅ Suggestions:\n",
      "  - Include projects that specifically utilize generative AI models, detailing the model architecture, training data, and achieved results.\n",
      "  - Mention any experience with fine-tuning pre-trained generative models for specific tasks.\n",
      "  - Highlight any publications, personal projects, or contributions to open-source projects related to generative AI.\n"
     ]
    }
   ],
   "source": [
    "for item in resume_weakness:\n",
    "    print(f\"\\n🔧 Skill: {item['skill']}\")\n",
    "    print(f\"❌ Weakness: {item['detail']}\")\n",
    "    print(f\"📌 Example: {item['example']}\")\n",
    "    print(\"✅ Suggestions:\")\n",
    "    for s in item['suggestions']:\n",
    "        print(f\"  - {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "106d948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skill: Mlops\n",
      "✅ Suggestions:\n",
      "  - Mention experience with containerization tools like Docker or Kubernetes.\n",
      "  - Include experience with CI/CD pipelines for model deployment.\n",
      "  - Add information about model monitoring and performance tracking tools.\n",
      "📌 Example addition: Implemented CI/CD pipelines using Jenkins to automate model retraining and deployment, reducing deployment time by 50% and ensuring consistent performance monitoring.\n",
      "\n",
      "🔧 Skill: Devops\n",
      "✅ Suggestions:\n",
      "  - Include any experience with cloud platforms (AWS, Azure, GCP) that might involve infrastructure management or deployment.\n",
      "  - Mention any experience with containerization technologies like Docker or orchestration tools like Kubernetes.\n",
      "  - If any projects involved automation of deployment or testing, highlight those aspects.\n",
      "📌 Example addition: Automated deployment of the Gemstone Price Predictor using Docker and GitHub Actions, resulting in a 20% reduction in deployment time.\n",
      "\n",
      "🔧 Skill: GenerativeAI\n",
      "✅ Suggestions:\n",
      "  - Include projects that specifically utilize generative models such as GANs, VAEs, or transformers for tasks like text generation, image synthesis, or data augmentation.\n",
      "  - Mention experience with prompt engineering and the use of specific generative AI platforms or APIs (e.g., OpenAI API, TensorFlow/PyTorch generative model libraries).\n",
      "  - Quantify the impact of any generative AI applications, such as improved efficiency, cost savings, or enhanced user engagement.\n",
      "📌 Example addition: Developed a text summarization model using a pre-trained transformer architecture (e.g., BART, T5) fine-tuned on a dataset of 5,000+ articles, achieving a ROUGE score increase of 15% compared to baseline models.\n"
     ]
    }
   ],
   "source": [
    "for skill, suggestion_data in improvement_suggestions.items():\n",
    "    print(f\"\\n🔧 Skill: {skill}\")\n",
    "    \n",
    "    print(\"✅ Suggestions:\")\n",
    "    for suggestion in suggestion_data.get(\"suggestions\", []):\n",
    "        print(f\"  - {suggestion}\")\n",
    "    \n",
    "    print(f\"📌 Example addition: {suggestion_data.get('example', 'No example provided.')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_skills_jd(jd_text):\n",
    "\"Extract skills from job description\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "jd_text = \"\"\"\n",
    "Job Title: Data Scientist\n",
    "Location: Remote / Bangalore, India\n",
    "Job Type: Full-time\n",
    "\n",
    "About the Role:\n",
    "We are seeking a Data Scientist who is passionate about using data to solve real-world problems and drive strategic decisions. You'll work closely with business, product, and engineering teams to uncover insights, build predictive models, and design experiments that impact millions of users.\n",
    "\n",
    "Key Responsibilities:\n",
    "- Analyze structured and unstructured data from multiple sources to extract meaningful insights.\n",
    "- Build machine learning models for prediction, classification, segmentation, and recommendation.\n",
    "- Design A/B tests and evaluate the performance of models and features.\n",
    "- Communicate findings clearly to stakeholders using dashboards, reports, and visualizations.\n",
    "- Collaborate with data engineers and software developers to deploy scalable data solutions.\n",
    "- Monitor model performance and perform periodic model retraining.\n",
    "\n",
    "Required Skills & Qualifications:\n",
    "- Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or related field.\n",
    "- 2+ years of experience in data science or a similar role.\n",
    "- Strong knowledge of Python, SQL, and machine learning libraries like scikit-learn, TensorFlow, or PyTorch.\n",
    "- Hands-on experience with data analysis and visualization tools such as Pandas, Matplotlib, Seaborn, or Tableau.\n",
    "- Understanding of statistical modeling, hypothesis testing, and experimental design.\n",
    "- Experience working with large datasets and cloud platforms (AWS, GCP, or Azure).\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "            Extract a comprehensive list of technical skills, technologies, and competencies required from this job description. \n",
    "            Format the output as a Python list of strings. Only include the list, nothing else.\n",
    "            \n",
    "            Job Description:\n",
    "            {jd_text}\n",
    "            \"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_text = response.content\n",
    "cleaned = re.sub(r\"```python|```\", \"\",skill_text).strip()\n",
    "\n",
    "jd_skills = eval(cleaned)\n",
    "print(jd_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ee0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"\n",
    "Utkarsh Raj\n",
    "Email: utkarsh@example.com | Phone: +91-9876543210 | Location: Rohtak, Haryana, India\n",
    "LinkedIn: www.linkedin.com/in/utkarsh9911 | GitHub: github.com/utkarshraj99\n",
    "\n",
    "Objective:\n",
    "Aspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.\n",
    "\n",
    "Education:\n",
    "Bachelor of Science in Computer Science (2021 – 2025)\n",
    "Maharshi Dayanand University, Rohtak, Haryana\n",
    "\n",
    "Skills:\n",
    "- Programming Languages: Python, SQL\n",
    "- Libraries & Tools: Pandas, NumPy, Scikit-learn, TensorFlow, Matplotlib, Seaborn, NLTK, SpaCy\n",
    "- MLOps Tools: DVC, MLflow, Apache Airflow, Docker, Git\n",
    "- Web Development: Flask, Streamlit, FastAPI\n",
    "- Cloud Platforms: Google Cloud Storage\n",
    "- Version Control: Git, GitHub\n",
    "- Data Engineering: YAML, JSON, CSV handling, Logging & Error Handling\n",
    "\n",
    "Projects:\n",
    "\n",
    "1. Stock Price Prediction using LSTM\n",
    "   - Built and trained an LSTM model using historical Apple stock data via yfinance\n",
    "   - Performed data preprocessing, scaling, and model evaluation\n",
    "   - Technologies: TensorFlow, Pandas, Matplotlib\n",
    "\n",
    "2. Resume Analyzer & Interview Bot\n",
    "   - Built a Streamlit app that evaluates resumes, gives ATS scores, and suggests improvements\n",
    "   - Includes features to generate interview questions and analyze job descriptions\n",
    "   - Integrated RAG-based Q&A with LLMs\n",
    "\n",
    "3. Customer Lifetime Value Prediction (CLTV)\n",
    "   - Performed RFM segmentation and applied BetaGeoFitter and GammaGamma models\n",
    "   - Developed marketing strategy recommendations for each customer cluster\n",
    "\n",
    "4. Hate Speech Detection (NLP)\n",
    "   - Created a dataset pipeline with MongoDB, Zip extraction, and preprocessing\n",
    "   - Built models to classify hate speech in tweets using logistic regression and NLP techniques\n",
    "\n",
    "Certifications:\n",
    "- AI For Everyone – Coursera\n",
    "- Data Science & Machine Learning – Kaggle Learn\n",
    "\n",
    "Achievements:\n",
    "- Completed over 10 real-world data science projects\n",
    "- Contributed to open-source ML templates using DVC and MLflow\n",
    "\n",
    "Languages:\n",
    "- English (Intermediate), Hindi (Native)\n",
    "\n",
    "Declaration:\n",
    "I hereby declare that the above information is true to the best of my knowledge.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc63c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ccba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(text):\n",
    "    \"\"\"Create a simpler vector store for skill analysis\"\"\"\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum size of each chunk\n",
    "    chunk_overlap=200,    # Overlap between chunks to maintain context\n",
    "    length_function=len ) # Function to measure chunk length\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def analyze_skills(ra_chain, skill):\n",
    "    \n",
    "    \"\"\"Analyze a single skill using the RAG chain and return skill, score, and cleaned reasoning.\"\"\"\n",
    "        \n",
    "        # Ask the chain for evaluation of the skill\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by reasoning\"\n",
    "    response = ra_chain.invoke({\"input\": query})\n",
    "\n",
    "        # Extract numeric score from the response\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1)) if match else 0\n",
    "        # final_score = min(score, 10)\n",
    "\n",
    "        # Clean up the reasoning part\n",
    "    reasoning_raw = response['answer']\n",
    "    reasoning_lines = [line.strip() for line in reasoning_raw.split('\\n') if line.strip()]\n",
    "    raw_reasoning = \" \".join(reasoning_lines)\n",
    "\n",
    "        # Remove leading score and optional symbols\n",
    "    reasoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "\n",
    "    return skill, min(score, 10), reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "def90a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke({\"query\": \"What skills does the resume show in MLOps?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be75290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the resume, Utkarsh Raj has experience with the following MLOps tools:\n",
      "\n",
      "*   DVC\n",
      "*   MLflow\n",
      "*   Apache Airflow\n",
      "*   Docker\n",
      "*   Git\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c21254",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6951997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "{'Python': 9, 'Java': 0, 'React': 0, 'PostgreSQL': 0, 'Cloud Computing (AWS/Azure/GCP)': 2, 'Leadership': 0, 'Project Management': 0, 'Machine Learning': 9}\n",
      "{'Python': 'The candidate explicitly lists Python as a programming language under the \"Skills\" section. The extensive list of libraries and tools also implies a strong proficiency in Python.', 'Java': 'The document does not mention Java.', 'React': 'The provided text does not mention React at all.', 'PostgreSQL': 'Reasoning: PostgreSQL is not mentioned anywhere in the provided document.', 'Cloud Computing (AWS/Azure/GCP)': 'The candidate only mentions Google Cloud Storage in the skills section. There is no indication of proficiency, or even exposure, to cloud computing beyond storage.', 'Leadership': 'The candidate does not mention proficiency in Leadership.', 'Project Management': \"Project management proficiency is not explicitly mentioned. While the candidate lists completed projects, there's no discussion of project management methodologies or experience.\", 'Machine Learning': 'The candidate explicitly mentions \"Data Science & Machine Learning\" certification, \"building machine learning models\" in their objective, lists multiple ML libraries & tools, and details ML implementations in several projects. This demonstrates a high level of clarity in showcasing ML proficiency.'}\n",
      "False\n",
      "Candidate evaluated based on explicit resume content using semantic similarity and clear numeric scoring.\n",
      "['Java', 'React', 'PostgreSQL', 'Cloud Computing (AWS/Azure/GCP)', 'Leadership', 'Project Management']\n",
      "['Python', 'Machine Learning']\n",
      "['Java', 'React', 'PostgreSQL', 'Cloud Computing (AWS/Azure/GCP)', 'Leadership', 'Project Management']\n"
     ]
    }
   ],
   "source": [
    "skill_scores = {}\n",
    "skill_reasoning = {}\n",
    "missing_skills = []\n",
    "total_score = 0\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "vectorstore = create_vector_store(resume_text)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "     \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "from langchain.chains import create_retrieval_chain\n",
    "ra_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "skills_analayze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(executor.map(lambda skill: analyze_skills(ra_chain, skill), skills))\n",
    "\n",
    "\n",
    "for skill, score, reasoning in results:\n",
    "\n",
    "    skill_scores[skill] = score\n",
    "    skill_reasoning[skill] = reasoning\n",
    "    total_score = total_score + score\n",
    "    if score <=5:\n",
    "          missing_skills.append(skill)\n",
    "    \n",
    "    # print(f\"Raw response for {skill}: {response['answer']}\")\n",
    "    \n",
    "overall_score = int((total_score / (10 *len(skills)))*100)\n",
    "\n",
    "selected = overall_score >= 50\n",
    "\n",
    "reasoning = \"Candidate evaluated based on explicit resume content using semantic similarity and clear numeric scoring.\"\n",
    "strengths = [skill for skill, score in skill_scores.items() if score >= 7]\n",
    "improvement_areas = missing_skills if not selected else []\n",
    "\n",
    "print(overall_score)\n",
    "print(skill_scores)\n",
    "print(skill_reasoning)\n",
    "print(selected)\n",
    "print(reasoning)\n",
    "print(missing_skills)\n",
    "print(strengths)\n",
    "print(improvement_areas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0896c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaknesses  = []\n",
    "improvement_suggestions = {}\n",
    "\n",
    "analysis_result = {\n",
    "    \"missing_skill\": [\"Mlops\", \"Devops\", 'GenerativeAI']\n",
    "}\n",
    "\n",
    "for skill in analysis_result.get('missing_skill', []):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "\n",
    "    For your analysis, consider:\n",
    "    1. What's missing from the resume regarding this skill?\n",
    "    2. How could it be improved with specific examples?\n",
    "    3. What specific action items would make this skill stand out?\n",
    "\n",
    "    Resume Content:\n",
    "    {resume_text[:30000]}\n",
    "\n",
    "    Provide your response in this JSON format:\n",
    "    {{\n",
    "        \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "        \"improvement_suggestions\": [\n",
    "            \"Specific suggestion 1\",\n",
    "            \"Specific suggestion 2\",\n",
    "            \"Specific suggestion 3\"\n",
    "        ],\n",
    "        \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "    }}\n",
    "\n",
    "    Return only valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # ✅ Extract string answer\n",
    "    raw_json = response.content\n",
    "\n",
    "    # ✅ Remove backticks and 'json' label\n",
    "    cleaned_json = re.sub(r'^```json|```$', '', raw_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        # ✅ Parse string into dictionary\n",
    "        weakness_data = json.loads(cleaned_json)\n",
    "\n",
    "        # ✅ Store in desired format\n",
    "        weakness_detail = {\n",
    "            \"skill\": skill,\n",
    "            \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "            \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "            \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "        }\n",
    "\n",
    "        weaknesses.append(weakness_detail)\n",
    "        improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed for skill {skill}: {e}\")\n",
    "        weaknesses.append({\n",
    "            \"skill\": skill,\n",
    "            \"detail\": raw_json[:200],  # fallback: first 200 characters\n",
    "            \n",
    "            \"example\": \"\"\n",
    "        })\n",
    "\n",
    "resume_weakness = weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276d47fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skill: Mlops\n",
      "❌ Weakness: The resume lists MLOps tools but lacks demonstrable evidence of using them effectively in a complete MLOps workflow. It doesn't showcase practical application beyond simply knowing the tool names.\n",
      "📌 Example: Implemented a CI/CD pipeline using GitHub Actions, Docker, and MLflow to automate model retraining and deployment, resulting in a 30% reduction in model deployment time.\n",
      "✅ Suggestions:\n",
      "  - Quantify the impact of using MLOps tools. Instead of just stating the tools used, highlight how their use improved model deployment frequency, reduced errors, or enhanced model performance.\n",
      "  - Focus on showcasing specific MLOps workflows implemented, detailing the end-to-end process. For example, explicitly describe the process of model versioning, CI/CD pipeline automation, and monitoring infrastructure used.\n",
      "  - Replace generic descriptions with quantifiable achievements. For example, instead of 'Contributed to open-source ML templates using DVC and MLflow,' provide metrics on usage or adoption of those templates.\n",
      "\n",
      "🔧 Skill: Devops\n",
      "❌ Weakness: The resume lists DevOps tools, but lacks context on how they were used to implement DevOps practices. It reads more like a list of technologies rather than demonstrating practical application in a DevOps context like CI/CD, Infrastructure as Code, or automation.\n",
      "📌 Example: Implemented a CI/CD pipeline using GitHub Actions and Docker to automate the build, test, and deployment of the Resume Analyzer & Interview Bot, reducing deployment time by 40% and improving release frequency.\n",
      "✅ Suggestions:\n",
      "  - Quantify the impact of using DevOps tools. Instead of just listing them, describe how they improved efficiency, reduced errors, or accelerated deployments.\n",
      "  - Include details about experience with CI/CD pipelines. Mention the specific tools used (e.g., Jenkins, GitLab CI, CircleCI) and the deployment strategies implemented (e.g., blue/green deployments, canary releases).\n",
      "  - Showcase experience with Infrastructure as Code (IaC) using tools like Terraform or CloudFormation. Describe how infrastructure was provisioned and managed programmatically, enabling automation and version control.\n",
      "\n",
      "🔧 Skill: GenerativeAI\n",
      "❌ Weakness: The resume mentions integrating RAG-based Q&A with LLMs in a project but lacks specific details about experience with Generative AI models, techniques, or prompt engineering. The skills section doesn't directly address Generative AI, making it difficult to assess the candidate's proficiency in this specific area.\n",
      "📌 Example: Skills: ... Generative AI (GPT-4, Llama 2), Prompt Engineering, Fine-tuning, RAG; Projects: Resume Analyzer & Interview Bot: Improved interview bot accuracy by 15% by implementing advanced prompt engineering techniques with GPT-4, resulting in more relevant and insightful responses based on the job description and resume context.\n",
      "✅ Suggestions:\n",
      "  - Explicitly mention Generative AI skills in the skills section, listing specific models (e.g., GPT-3, GPT-4, Llama 2, Stable Diffusion, DALL-E 2) and techniques (e.g., prompt engineering, fine-tuning, reinforcement learning from human feedback (RLHF)).\n",
      "  - Quantify the results of the RAG-based Q&A project. For example, mention accuracy improvements, reduction in hallucination, or user satisfaction metrics.\n",
      "  - Showcase understanding of responsible AI practices related to Generative AI, such as bias mitigation, safety protocols, and ethical considerations.\n"
     ]
    }
   ],
   "source": [
    "for item in resume_weakness:\n",
    "    print(f\"\\n🔧 Skill: {item['skill']}\")\n",
    "    print(f\"❌ Weakness: {item['detail']}\")\n",
    "    print(f\"📌 Example: {item['example']}\")\n",
    "    print(\"✅ Suggestions:\")\n",
    "    for s in item['suggestions']:\n",
    "        print(f\"  - {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df07da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result = {'strengths':{'python', 'machine learning'}}\n",
    "extracted_skills = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" \n",
    "]\n",
    "num_questions = 3\n",
    "difficulty = 'Medium'\n",
    "question_types = ['technical', 'Behavioural']\n",
    "context = f\"\"\"\n",
    "Resume Content:\n",
    "{resume_text[:2000]}...\n",
    "            \n",
    "Skills to focus on: {', '.join(extracted_skills)}\n",
    "            \n",
    "Strengths: {', '.join(analysis_result.get('strengths', []))}\n",
    "            \n",
    "Areas for improvement: {', '.join(missing_skills)}\n",
    "            \"\"\"\n",
    "            \n",
    "prompt = f\"\"\"\n",
    "Generate {num_questions} personalized {difficulty.lower()} level interview questions for this candidate \n",
    "based on their resume and skills. Include only the following question types: {', '.join(question_types)}.\n",
    "            \n",
    "For each question:\n",
    "1. Clearly label the question type\n",
    "2. Make the question specific to their background and skills\n",
    "3. For coding questions, include a clear problem statement\n",
    "            \n",
    "{context}\n",
    "            \n",
    "Format the response as a list of tuples with the question type and the question itself.\n",
    "Each tuple should be in the format: (\"Question Type\", \"Full Question Text\")\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "response =  llm.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c944f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three interview questions tailored for Utkarsh Raj, based on his resume and skills, in the requested format:\n",
      "\n",
      "[\n",
      "    (\"Technical\", \"Based on your project 'Hate Speech Detection (NLP)', describe a situation where you encountered imbalanced classes in the dataset. Explain what techniques you used to address this imbalance and how they affected the performance of your logistic regression model. Provide sample code in python of how you handled class imbalance. \"),\n",
      "    (\"Behavioural\", \"You've worked on multiple data science projects, including the 'Customer Lifetime Value Prediction (CLTV)' project. Describe a time when you had to communicate complex analytical findings and marketing strategy recommendations to stakeholders with limited technical knowledge. How did you tailor your communication style to ensure they understood the key insights and could make informed decisions?\"),\n",
      "    (\"Technical\", \"In your resume, you mentioned using DVC for MLOps in your projects. Imagine you are working on a project with a team and are using DVC to manage different versions of your models and datasets. Could you describe a scenario where you encountered conflicting changes between team members using DVC, and how you resolved the conflict, including specific DVC commands and Python code?\" )\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "questions_text = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cae3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    (\"Technical\", \"Based on your project 'Hate Speech Detection (NLP)', describe a situation where you encountered imbalanced classes in the dataset. Explain what techniques you used to address this imbalance and how they affected the performance of your logistic regression model. Provide sample code in python of how you handled class imbalance. \"),\n",
      "    (\"Behavioural\", \"You've worked on multiple data science projects, including the 'Customer Lifetime Value Prediction (CLTV)' project. Describe a time when you had to communicate complex analytical findings and marketing strategy recommendations to stakeholders with limited technical knowledge. How did you tailor your communication style to ensure they understood the key insights and could make informed decisions?\"),\n",
      "    (\"Technical\", \"In your resume, you mentioned using DVC for MLOps in your projects. Imagine you are working on a project with a team and are using DVC to manage different versions of your models and datasets. Could you describe a scenario where you encountered conflicting changes between team members using DVC, and how you resolved the conflict, including specific DVC commands and Python code?\" )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "questions_text = response.content\n",
    "questions = []\n",
    "\n",
    "# Step 1: Remove any extra explanation text before the list\n",
    "match = re.search(r\"\\[\\s*\\(\", questions_text, re.DOTALL)\n",
    "if match:\n",
    "    start_index = match.start()\n",
    "    questions_text = questions_text[start_index:]\n",
    "\n",
    "# Step 2: Clean up Markdown or Python syntax\n",
    "questions_text = re.sub(r\"```(?:python)?|```\", \"\", questions_text).strip()\n",
    "print(questions_text)\n",
    "\n",
    "# Step 3: Safely evaluate the string into a Python list\n",
    "try:\n",
    "    questions_list = eval(questions_text)\n",
    "    questions = []\n",
    "    for question_type, question in questions_list:\n",
    "        for requested_type in question_types:\n",
    "            if requested_type.lower() in question_type.lower():\n",
    "                questions.append((question_type.strip(), question.strip()))\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Parsing failed: {e}\")\n",
    "    questions = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81d34ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Technical', \"Based on your project 'Hate Speech Detection (NLP)', describe a situation where you encountered imbalanced classes in the dataset. Explain what techniques you used to address this imbalance and how they affected the performance of your logistic regression model. Provide sample code in python of how you handled class imbalance. \"), ('Behavioural', \"You've worked on multiple data science projects, including the 'Customer Lifetime Value Prediction (CLTV)' project. Describe a time when you had to communicate complex analytical findings and marketing strategy recommendations to stakeholders with limited technical knowledge. How did you tailor your communication style to ensure they understood the key insights and could make informed decisions?\"), ('Technical', 'In your resume, you mentioned using DVC for MLOps in your projects. Imagine you are working on a project with a team and are using DVC to manage different versions of your models and datasets. Could you describe a scenario where you encountered conflicting changes between team members using DVC, and how you resolved the conflict, including specific DVC commands and Python code?')]\n",
      "'tuple' object has no attribute 'strip'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    questions_list = eval(questions_text1)\n",
    "    print(questions_list)\n",
    "    print(questions_list[0].strip())\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e41cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Technical', 'Q1 about hate speech project...'), ('Technical', 'Q3 about DVC and MLOps...')]\n"
     ]
    }
   ],
   "source": [
    "abc = [\n",
    "    (\"Technical\", \"Q1 about hate speech project...\"),\n",
    "    (\"Behavioural\", \"Q2 about communication...\"),\n",
    "    (\"Technical\", \"Q3 about DVC and MLOps...\")\n",
    "]\n",
    "question_types = [\"Technical\"]\n",
    "\n",
    "questions = []\n",
    "\n",
    "for question_type, question in abc:\n",
    "    for requested_type in question_types:\n",
    "        if requested_type.lower() in question_type.lower():\n",
    "            questions.append((question_type.strip(), question.strip()))\n",
    "            \n",
    "print(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f4b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
