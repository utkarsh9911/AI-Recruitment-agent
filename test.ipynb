{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b086dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa36fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UTKARSH\\.conda\\envs\\aiagent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import io\n",
    "import google.generativeai as genaiI\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\AI-Recruitment-agent\\datascienceresume32 - Google Docs.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23703b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loder = PyPDFLoader(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c660501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loder.load()\n",
    "\n",
    "# print(documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f5af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEYY = os.getenv(\"GEMINI_API\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0208ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke('hii')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440f7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum size of each chunk\n",
    "    chunk_overlap=200,    # Overlap between chunks to maintain context\n",
    "    length_function=len  # Function to measure chunk length\n",
    "    \n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "texts = [doc.page_content for doc in chunks]  # Extract text from Document objects\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be38b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23132235",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d51ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "ra_chain = create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51b8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ra_chain.invoke({\"input\": 'What is my fathers name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62240b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the provided context does not contain information about your father's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39cf8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "●  Data Science Certification  -  Coursera  November 2023 \n",
      " ●  Earned Badge of Python and SQL  –  HackerRank  January 2024 \n",
      " ●  Five Star Python Coder -  HackerRank  May 2024 \n",
      " ADDITIONAL INFORMA TION \n",
      " ●  Location :  Delhi \n",
      " ●  Availability :  Immediate Joiner\n"
     ]
    }
   ],
   "source": [
    "print(response['context'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fa2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_to_analyze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c81960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_scores = []\n",
    "# for skill in skills_to_analyze:\n",
    "#     query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "#     response = retrieval_chain.invoke({\"input\": query})\n",
    "#     match = re.search(r'(\\d+)', response['answer'])\n",
    "#     score = int(match.group(1) if match else 0)\n",
    "#     reasoning_parts = response['answer'].split('\\n', 1)\n",
    "#     if len(reasoning_parts) > 1:\n",
    "            \n",
    "#             reasoning = reasoning_parts[1].strip()\n",
    "#     else:\n",
    "#             reasoning = response['answer'].strip()\n",
    "#     # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "#     final_score = min(score, 10)\n",
    "#     skill_scores.append(final_score)\n",
    "#     print(f\"  Score for {skill}: {final_score}/10\")\n",
    "#     print(f\"  Reasoning: {reasoning}\")\n",
    "# # Overall score calculation\n",
    "    \n",
    "# # overall_score = sum(skill_scores)\n",
    "# # n = len(skill_scores)\n",
    "# # print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "# # find overll score\n",
    "# print(skill_scores)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb324213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Python: 9/10\n",
      "  Reasoning: The candidate explicitly mentions Python as a programming language under \"TECHNICAL SKILLS,\" has earned a \"Five Star Python Coder\" badge from HackerRank, and used Python in multiple projects, providing ample evidence of their proficiency.\n",
      "  Score for Java: 0/10\n",
      "  Reasoning: The candidate does not mention any proficiency in Java in the provided context.\n",
      "  Score for React: 0/10\n",
      "  Reasoning: React is not mentioned in the provided text.\n",
      "  Score for PostgreSQL: 0/10\n",
      "  Reasoning: PostgreSQL is not mentioned at all.\n",
      "  Score for Cloud Computing (AWS/Azure/GCP): 0/10\n",
      "  Reasoning: The candidate does not mention any cloud computing platforms (AWS/Azure/GCP) at all.\n",
      "  Score for Leadership: 0/10\n",
      "  Reasoning: The candidate does not mention proficiency in Leadership in the provided context.\n",
      "  Score for Project Management: 0/10\n",
      "  Reasoning: The candidate does not mention proficiency in project management.\n",
      "  Score for Machine Learning: 10/10\n",
      "  Reasoning: Reasoning: The candidate explicitly lists \"Machine Learning\" under the \"Data Science\" section of TECHNICAL SKILLS. Furthermore, the candidate details multiple projects using machine learning techniques (Gemstone Price Predictor, Stock Price Forecasting, MaternAI), providing specific performance metrics (accuracy percentages) for these models. This demonstrates a high level of understanding and practical application of machine learning principles.\n",
      "Overall Score: 19/80\n"
     ]
    }
   ],
   "source": [
    "# final code\n",
    "skill_scores = []\n",
    "for skill in skills_to_analyze:\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "    response = ra_chain.invoke({\"input\": query})\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1) if match else 0)\n",
    "    reasoning_parts = response['answer']\n",
    "    reasining_lines = [line.strip() for line in reasoning_parts.split('\\n') if line.strip()]\n",
    "    \n",
    "    raw_reasoning = ' '.join(reasining_lines)\n",
    "   \n",
    "    final_resoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "    # if len(reasoning_parts) > 1:\n",
    "            \n",
    "    #         reasoning = reasoning_parts[1].strip()\n",
    "    # else:\n",
    "    #         reasoning = response['answer'].strip()\n",
    "    # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "    final_score = min(score, 10)\n",
    "    skill_scores.append(final_score)\n",
    "    print(f\"  Score for {skill}: {final_score}/10\")\n",
    "    print(f\"  Reasoning: {final_resoning}\")\n",
    "# Overall score calculation\n",
    "    \n",
    "overall_score = sum(skill_scores)\n",
    "n = len(skill_scores)\n",
    "print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaknesses  = []\n",
    "improvement_suggestions = {}\n",
    "\n",
    "analysis_result = {\n",
    "    \"missing_skill\": [\"Mlops\", \"Devops\", 'GenerativeAI']\n",
    "}\n",
    "\n",
    "for skill in analysis_result.get('missing_skill', []):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "\n",
    "    For your analysis, consider:\n",
    "    1. What's missing from the resume regarding this skill?\n",
    "    2. How could it be improved with specific examples?\n",
    "    3. What specific action items would make this skill stand out?\n",
    "\n",
    "    Provide your response in this JSON format:\n",
    "    {{\n",
    "        \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "        \"improvement_suggestions\": [\n",
    "            \"Specific suggestion 1\",\n",
    "            \"Specific suggestion 2\",\n",
    "            \"Specific suggestion 3\"\n",
    "        ],\n",
    "        \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "    }}\n",
    "\n",
    "    Return only valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ra_chain.invoke({\"input\": prompt})\n",
    "    \n",
    "    # ✅ Extract string answer\n",
    "    raw_json = response['answer']\n",
    "\n",
    "    # ✅ Remove backticks and 'json' label\n",
    "    cleaned_json = re.sub(r'^```json|```$', '', raw_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        # ✅ Parse string into dictionary\n",
    "        weakness_data = json.loads(cleaned_json)\n",
    "\n",
    "        # ✅ Store in desired format\n",
    "        weakness_detail = {\n",
    "            \"skill\": skill,\n",
    "            \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "            \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "            \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "        }\n",
    "\n",
    "        weaknesses.append(weakness_detail)\n",
    "        improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed for skill {skill}: {e}\")\n",
    "        weaknesses.append({\n",
    "            \"skill\": skill,\n",
    "            \"detail\": raw_json[:200],  # fallback: first 200 characters\n",
    "            \n",
    "            \"example\": \"\"\n",
    "        })\n",
    "\n",
    "resume_weakness = weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "333c755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skill: Mlops\n",
      "❌ Weakness: The resume is weak in demonstrating proficiency in MLOps because it lacks any explicit mention of MLOps practices, tools, or experience with deploying and managing machine learning models in a production environment. While the resume highlights model building and accuracy, it doesn't showcase understanding of the complete ML lifecycle.\n",
      "📌 Example: Implemented CI/CD pipeline using GitHub Actions and Docker to automate model deployment for the Gemstone Price Predictor, reducing deployment time by 50%.\n",
      "✅ Suggestions:\n",
      "  - Include experience with model deployment tools like Docker, Kubernetes, AWS SageMaker, or similar.\n",
      "  - Mention any involvement in model monitoring, retraining, or version control processes.\n",
      "  - Specify if any CI/CD pipelines were used for model deployment.\n",
      "\n",
      "🔧 Skill: Devops\n",
      "❌ Weakness: The resume is weak in demonstrating proficiency in DevOps because it lacks any explicit mention or demonstration of skills, tools, or experiences related to DevOps practices like CI/CD, containerization, infrastructure as code, or automation. While the projects showcase data science skills, they don't illustrate how the models were deployed or managed in a production environment, which are key aspects of DevOps.\n",
      "📌 Example: Implemented CI/CD pipeline using Jenkins and Docker to automate the deployment of the sentiment analysis model, reducing deployment time by 50% and improving system uptime by 15%.\n",
      "✅ Suggestions:\n",
      "  - Include a section specifically listing DevOps skills and tools, such as Docker, Kubernetes, Jenkins, Ansible, Terraform, AWS CloudFormation, Azure DevOps, or similar.\n",
      "  - Describe any experience with automating deployment pipelines, infrastructure management, or monitoring and logging systems.\n",
      "  - Quantify the impact of any DevOps-related implementations, such as reduced deployment time or improved system uptime.\n",
      "\n",
      "🔧 Skill: GenerativeAI\n",
      "❌ Weakness: The resume lacks any explicit mention or demonstration of skills and experience in Generative AI. While NLP and chatbot development are related, they do not directly showcase proficiency in Generative AI models like GANs, diffusion models, or large language models used for content creation.\n",
      "📌 Example: Developed a generative model using GANs to create synthetic datasets for [application area], achieving a [quantifiable metric] improvement in downstream task performance.\n",
      "✅ Suggestions:\n",
      "  - Include projects that specifically utilize generative AI models, detailing the model architecture, training data, and achieved results.\n",
      "  - Mention any experience with fine-tuning pre-trained generative models for specific tasks.\n",
      "  - Highlight any publications, personal projects, or contributions to open-source projects related to generative AI.\n"
     ]
    }
   ],
   "source": [
    "for item in resume_weakness:\n",
    "    print(f\"\\n🔧 Skill: {item['skill']}\")\n",
    "    print(f\"❌ Weakness: {item['detail']}\")\n",
    "    print(f\"📌 Example: {item['example']}\")\n",
    "    print(\"✅ Suggestions:\")\n",
    "    for s in item['suggestions']:\n",
    "        print(f\"  - {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "106d948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skill: Mlops\n",
      "✅ Suggestions:\n",
      "  - Mention experience with containerization tools like Docker or Kubernetes.\n",
      "  - Include experience with CI/CD pipelines for model deployment.\n",
      "  - Add information about model monitoring and performance tracking tools.\n",
      "📌 Example addition: Implemented CI/CD pipelines using Jenkins to automate model retraining and deployment, reducing deployment time by 50% and ensuring consistent performance monitoring.\n",
      "\n",
      "🔧 Skill: Devops\n",
      "✅ Suggestions:\n",
      "  - Include any experience with cloud platforms (AWS, Azure, GCP) that might involve infrastructure management or deployment.\n",
      "  - Mention any experience with containerization technologies like Docker or orchestration tools like Kubernetes.\n",
      "  - If any projects involved automation of deployment or testing, highlight those aspects.\n",
      "📌 Example addition: Automated deployment of the Gemstone Price Predictor using Docker and GitHub Actions, resulting in a 20% reduction in deployment time.\n",
      "\n",
      "🔧 Skill: GenerativeAI\n",
      "✅ Suggestions:\n",
      "  - Include projects that specifically utilize generative models such as GANs, VAEs, or transformers for tasks like text generation, image synthesis, or data augmentation.\n",
      "  - Mention experience with prompt engineering and the use of specific generative AI platforms or APIs (e.g., OpenAI API, TensorFlow/PyTorch generative model libraries).\n",
      "  - Quantify the impact of any generative AI applications, such as improved efficiency, cost savings, or enhanced user engagement.\n",
      "📌 Example addition: Developed a text summarization model using a pre-trained transformer architecture (e.g., BART, T5) fine-tuned on a dataset of 5,000+ articles, achieving a ROUGE score increase of 15% compared to baseline models.\n"
     ]
    }
   ],
   "source": [
    "for skill, suggestion_data in improvement_suggestions.items():\n",
    "    print(f\"\\n🔧 Skill: {skill}\")\n",
    "    \n",
    "    print(\"✅ Suggestions:\")\n",
    "    for suggestion in suggestion_data.get(\"suggestions\", []):\n",
    "        print(f\"  - {suggestion}\")\n",
    "    \n",
    "    print(f\"📌 Example addition: {suggestion_data.get('example', 'No example provided.')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b73ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec0d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474306f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def90a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be75290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6951997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d20faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d47fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07da76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c944f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
