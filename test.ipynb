{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b086dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa36fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UTKARSH\\.conda\\envs\\aiagent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import io\n",
    "import google.generativeai as genaiI\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\AI-Recruitment-agent\\datascienceresume32 - Google Docs.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23703b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loder = PyPDFLoader(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c660501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loder.load()\n",
    "\n",
    "# print(documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f5af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEYY = os.getenv(\"GEMINI_API\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da0208ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke('hii')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440f7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum size of each chunk\n",
    "    chunk_overlap=200,    # Overlap between chunks to maintain context\n",
    "    length_function=len  # Function to measure chunk length\n",
    "    \n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "texts = [doc.page_content for doc in chunks]  # Extract text from Document objects\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be38b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23132235",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0be5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d51ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "ra_chain = create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51b8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ra_chain.invoke({\"input\": 'What is my fathers name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e62240b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but this document does not contain information about the father's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cf8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚óè  Data Science Certification  -  Coursera  November 2023 \n",
      " ‚óè  Earned Badge of Python and SQL  ‚Äì  HackerRank  January 2024 \n",
      " ‚óè  Five Star Python Coder -  HackerRank  May 2024 \n",
      " ADDITIONAL INFORMA TION \n",
      " ‚óè  Location :  Delhi \n",
      " ‚óè  Availability :  Immediate Joiner\n"
     ]
    }
   ],
   "source": [
    "print(response['context'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fa2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_to_analyze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c81960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_scores = []\n",
    "# for skill in skills_to_analyze:\n",
    "#     query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "#     response = retrieval_chain.invoke({\"input\": query})\n",
    "#     match = re.search(r'(\\d+)', response['answer'])\n",
    "#     score = int(match.group(1) if match else 0)\n",
    "#     reasoning_parts = response['answer'].split('\\n', 1)\n",
    "#     if len(reasoning_parts) > 1:\n",
    "            \n",
    "#             reasoning = reasoning_parts[1].strip()\n",
    "#     else:\n",
    "#             reasoning = response['answer'].strip()\n",
    "#     # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "#     final_score = min(score, 10)\n",
    "#     skill_scores.append(final_score)\n",
    "#     print(f\"  Score for {skill}: {final_score}/10\")\n",
    "#     print(f\"  Reasoning: {reasoning}\")\n",
    "# # Overall score calculation\n",
    "    \n",
    "# # overall_score = sum(skill_scores)\n",
    "# # n = len(skill_scores)\n",
    "# # print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "# # find overll score\n",
    "# print(skill_scores)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb324213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score for Python: 10/10\n",
      "  Reasoning: The candidate explicitly lists Python under \"Programming Languages,\" earned a \"Five Star Python Coder\" badge, and has multiple projects and experiences demonstrating Python skills.\n",
      "  Score for Java: 0/10\n",
      "  Reasoning: The document does not mention Java at all.\n",
      "  Score for React: 0/10\n",
      "  Reasoning: React is not mentioned in the provided context.\n",
      "  Score for PostgreSQL: 0/10\n",
      "  Reasoning: The candidate does not mention PostgreSQL.\n",
      "  Score for Cloud Computing (AWS/Azure/GCP): 0/10\n",
      "  Reasoning: The candidate does not mention any Cloud Computing skills (AWS/Azure/GCP) in the provided context.\n",
      "  Score for Leadership: 0/10\n",
      "  Reasoning: The candidate does not mention leadership skills or experience in the provided context.\n",
      "  Score for Project Management: 0/10\n",
      "  Reasoning: The candidate does not mention proficiency in Project Management.\n",
      "  Score for Machine Learning: 10/10\n",
      "  Reasoning: /10. The candidate mentions Machine Learning under \"Technical Skills\", and implements Machine Learning in multiple projects and previous work experience.\n",
      "Overall Score: 20/80\n"
     ]
    }
   ],
   "source": [
    "# final code\n",
    "skill_scores = []\n",
    "for skill in skills_to_analyze:\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by resoning\"\n",
    "    response = ra_chain.invoke({\"input\": query})\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1) if match else 0)\n",
    "    reasoning_parts = response['answer']\n",
    "    reasining_lines = [line.strip() for line in reasoning_parts.split('\\n') if line.strip()]\n",
    "    \n",
    "    raw_reasoning = ' '.join(reasining_lines)\n",
    "   \n",
    "    final_resoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "    # if len(reasoning_parts) > 1:\n",
    "            \n",
    "    #         reasoning = reasoning_parts[1].strip()\n",
    "    # else:\n",
    "    #         reasoning = response['answer'].strip()\n",
    "    # reasoning = response['answer'].split('\\n', 1)[1].strip() if '.' in response['answer'] and len(response['answer'].split('.')) > 1 else \"\"\n",
    "    final_score = min(score, 10)\n",
    "    skill_scores.append(final_score)\n",
    "    print(f\"  Score for {skill}: {final_score}/10\")\n",
    "    print(f\"  Reasoning: {final_resoning}\")\n",
    "# Overall score calculation\n",
    "    \n",
    "overall_score = sum(skill_scores)\n",
    "n = len(skill_scores)\n",
    "print(f\"Overall Score: {overall_score}/{n * 10}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7412d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaknesses  = []\n",
    "improvement_suggestions = {}\n",
    "\n",
    "analysis_result = {\n",
    "    \"missing_skill\": [\"Mlops\", \"Devops\", 'GenerativeAI']\n",
    "}\n",
    "\n",
    "for skill in analysis_result.get('missing_skill', []):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "\n",
    "    For your analysis, consider:\n",
    "    1. What's missing from the resume regarding this skill?\n",
    "    2. How could it be improved with specific examples?\n",
    "    3. What specific action items would make this skill stand out?\n",
    "\n",
    "    Provide your response in this JSON format:\n",
    "    {{\n",
    "        \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "        \"improvement_suggestions\": [\n",
    "            \"Specific suggestion 1\",\n",
    "            \"Specific suggestion 2\",\n",
    "            \"Specific suggestion 3\"\n",
    "        ],\n",
    "        \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "    }}\n",
    "\n",
    "    Return only valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ra_chain.invoke({\"input\": prompt})\n",
    "    \n",
    "    # ‚úÖ Extract string answer\n",
    "    raw_json = response['answer']\n",
    "\n",
    "    # ‚úÖ Remove backticks and 'json' label\n",
    "    cleaned_json = re.sub(r'^```json|```$', '', raw_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ Parse string into dictionary\n",
    "        weakness_data = json.loads(cleaned_json)\n",
    "\n",
    "        # ‚úÖ Store in desired format\n",
    "        weakness_detail = {\n",
    "            \"skill\": skill,\n",
    "            \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "            \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "            \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "        }\n",
    "\n",
    "        weaknesses.append(weakness_detail)\n",
    "        improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed for skill {skill}: {e}\")\n",
    "        weaknesses.append({\n",
    "            \"skill\": skill,\n",
    "            \"detail\": raw_json[:200],  # fallback: first 200 characters\n",
    "            \n",
    "            \"example\": \"\"\n",
    "        })\n",
    "\n",
    "resume_weakness = weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333c755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Skill: Mlops\n",
      "‚ùå Weakness: The resume lacks explicit mention of MLOps practices. While some projects hint at components of MLOps (model deployment, version control), there's no direct evidence of a systematic approach to model building, deployment, monitoring, and maintenance.\n",
      "üìå Example: Implemented CI/CD pipelines using Jenkins to automate the deployment of the Gemstone Price Predictor model to a cloud-based platform, reducing deployment time by 50% and enabling continuous model monitoring.\n",
      "‚úÖ Suggestions:\n",
      "  - Explicitly list MLOps tools and platforms used (e.g., Docker, Kubernetes, CI/CD pipelines, model monitoring tools).\n",
      "  - Detail the deployment strategy for any of the models built, highlighting automation, scaling, and monitoring aspects.\n",
      "  - Quantify the impact of MLOps practices, such as reduced deployment time or improved model performance after deployment.\n",
      "\n",
      "üîß Skill: Devops\n",
      "‚ùå Weakness: The resume is completely missing any mention of DevOps related skills, tools, or experience. There is no evidence presented that the candidate has any proficiency in DevOps practices.\n",
      "üìå Example: Implemented CI/CD pipeline using Jenkins and Docker to automate the deployment of the NLP-driven sentiment analysis model, reducing deployment time by 50%.\n",
      "‚úÖ Suggestions:\n",
      "  - Include a section in the 'Technical Skills' mentioning DevOps tools like Docker, Kubernetes, AWS, Azure, or Jenkins if the candidate has experience with them.\n",
      "  - Add a project or describe an existing project (like the AI chatbot) where DevOps practices were used for deployment, scaling, or monitoring.\n",
      "  - If the candidate has experience with CI/CD pipelines, infrastructure as code, or containerization, explicitly mention these concepts with associated technologies.\n",
      "\n",
      "üîß Skill: GenerativeAI\n",
      "‚ùå Weakness: The resume lacks explicit mention or demonstration of skills related to Generative AI. While NLP and chatbot development are related, the resume doesn't showcase experience with models like GANs, diffusion models, or large language models used for content generation.\n",
      "üìå Example: Developed a text summarization tool using a pre-trained Transformer model, reducing content processing time by 50%.\n",
      "‚úÖ Suggestions:\n",
      "  - Include projects that utilize generative AI models for specific tasks, such as image generation, text summarization, or code generation.\n",
      "  - Mention experience with specific generative AI frameworks and libraries (e.g., Transformers, Stable Diffusion, etc.).\n",
      "  - Quantify the impact of any generative AI applications developed, such as improvements in content creation efficiency or user engagement.\n"
     ]
    }
   ],
   "source": [
    "for item in resume_weakness:\n",
    "    print(f\"\\nüîß Skill: {item['skill']}\")\n",
    "    print(f\"‚ùå Weakness: {item['detail']}\")\n",
    "    print(f\"üìå Example: {item['example']}\")\n",
    "    print(\"‚úÖ Suggestions:\")\n",
    "    for s in item['suggestions']:\n",
    "        print(f\"  - {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "106d948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Skill: Mlops\n",
      "‚úÖ Suggestions:\n",
      "  - Mention experience with containerization tools like Docker or Kubernetes.\n",
      "  - Include experience with CI/CD pipelines for model deployment.\n",
      "  - Add information about model monitoring and performance tracking tools.\n",
      "üìå Example addition: Implemented CI/CD pipelines using Jenkins to automate model retraining and deployment, reducing deployment time by 50% and ensuring consistent performance monitoring.\n",
      "\n",
      "üîß Skill: Devops\n",
      "‚úÖ Suggestions:\n",
      "  - Include any experience with cloud platforms (AWS, Azure, GCP) that might involve infrastructure management or deployment.\n",
      "  - Mention any experience with containerization technologies like Docker or orchestration tools like Kubernetes.\n",
      "  - If any projects involved automation of deployment or testing, highlight those aspects.\n",
      "üìå Example addition: Automated deployment of the Gemstone Price Predictor using Docker and GitHub Actions, resulting in a 20% reduction in deployment time.\n",
      "\n",
      "üîß Skill: GenerativeAI\n",
      "‚úÖ Suggestions:\n",
      "  - Include projects that specifically utilize generative models such as GANs, VAEs, or transformers for tasks like text generation, image synthesis, or data augmentation.\n",
      "  - Mention experience with prompt engineering and the use of specific generative AI platforms or APIs (e.g., OpenAI API, TensorFlow/PyTorch generative model libraries).\n",
      "  - Quantify the impact of any generative AI applications, such as improved efficiency, cost savings, or enhanced user engagement.\n",
      "üìå Example addition: Developed a text summarization model using a pre-trained transformer architecture (e.g., BART, T5) fine-tuned on a dataset of 5,000+ articles, achieving a ROUGE score increase of 15% compared to baseline models.\n"
     ]
    }
   ],
   "source": [
    "for skill, suggestion_data in improvement_suggestions.items():\n",
    "    print(f\"\\nüîß Skill: {skill}\")\n",
    "    \n",
    "    print(\"‚úÖ Suggestions:\")\n",
    "    for suggestion in suggestion_data.get(\"suggestions\", []):\n",
    "        print(f\"  - {suggestion}\")\n",
    "    \n",
    "    print(f\"üìå Example addition: {suggestion_data.get('example', 'No example provided.')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cc3b73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_jd(jd_text):\n",
    "    \"Extract skills from job description\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "    jd_text = \"\"\"\n",
    "    Job Title: Data Scientist\n",
    "    Location: Remote / Bangalore, India\n",
    "    Job Type: Full-time\n",
    "\n",
    "    About the Role:\n",
    "    We are seeking a Data Scientist who is passionate about using data to solve real-world problems and drive strategic decisions. You'll work closely with business, product, and engineering teams to uncover insights, build predictive models, and design experiments that impact millions of users.\n",
    "\n",
    "    Key Responsibilities:\n",
    "    - Analyze structured and unstructured data from multiple sources to extract meaningful insights.\n",
    "    - Build machine learning models for prediction, classification, segmentation, and recommendation.\n",
    "    - Design A/B tests and evaluate the performance of models and features.\n",
    "    - Communicate findings clearly to stakeholders using dashboards, reports, and visualizations.\n",
    "    - Collaborate with data engineers and software developers to deploy scalable data solutions.\n",
    "    - Monitor model performance and perform periodic model retraining.\n",
    "\n",
    "    Required Skills & Qualifications:\n",
    "    - Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or related field.\n",
    "    - 2+ years of experience in data science or a similar role.\n",
    "    - Strong knowledge of Python, SQL, and machine learning libraries like scikit-learn, TensorFlow, or PyTorch.\n",
    "    - Hands-on experience with data analysis and visualization tools such as Pandas, Matplotlib, Seaborn, or Tableau.\n",
    "    - Understanding of statistical modeling, hypothesis testing, and experimental design.\n",
    "    - Experience working with large datasets and cloud platforms (AWS, GCP, or Azure).\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "                Extract a comprehensive list of technical skills, technologies, and competencies required from this job description. \n",
    "                Format the output as a Python list of strings. Only include the list, nothing else.\n",
    "                \n",
    "                Job Description:\n",
    "                {jd_text}\n",
    "                \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    skill_text = response.content\n",
    "    cleaned = re.sub(r\"```python|```\", \"\",skill_text).strip()\n",
    "\n",
    "    jd_skills = eval(cleaned)\n",
    "    return jd_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "82ec0d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analysis', 'Machine Learning', 'Predictive Modeling', 'Classification', 'Segmentation', 'Recommendation Systems', 'A/B Testing', 'Model Evaluation', 'Data Visualization', 'Dashboard Creation', 'Report Generation', 'Statistical Modeling', 'Hypothesis Testing', 'Experimental Design', 'Model Deployment', 'Model Monitoring', 'Model Retraining', 'Python', 'SQL', 'scikit-learn', 'TensorFlow', 'PyTorch', 'Pandas', 'Matplotlib', 'Seaborn', 'Tableau', 'Cloud Platforms (AWS, GCP, or Azure)', 'Working with Large Datasets', 'Communication', 'Collaboration', 'Data Engineering', 'Software Development', 'Analyzing structured data', 'Analyzing unstructured data', 'Extracting meaningful insights']\n"
     ]
    }
   ],
   "source": [
    "print(extract_skills_jd(jd_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ee0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"\n",
    "Utkarsh Raj\n",
    "Email: utkarsh@example.com | Phone: +91-9876543210 | Location: Rohtak, Haryana, India\n",
    "LinkedIn: www.linkedin.com/in/utkarsh9911 | GitHub: github.com/utkarshraj99\n",
    "\n",
    "Objective:\n",
    "Aspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.\n",
    "\n",
    "Education:\n",
    "Bachelor of Science in Computer Science (2021 ‚Äì 2025)\n",
    "Maharshi Dayanand University, Rohtak, Haryana\n",
    "\n",
    "Skills:\n",
    "- Programming Languages: Python, SQL\n",
    "- Libraries & Tools: Pandas, NumPy, Scikit-learn, TensorFlow, Matplotlib, Seaborn, NLTK, SpaCy\n",
    "- MLOps Tools: DVC, MLflow, Apache Airflow, Docker, Git\n",
    "- Web Development: Flask, Streamlit, FastAPI\n",
    "- Cloud Platforms: Google Cloud Storage\n",
    "- Version Control: Git, GitHub\n",
    "- Data Engineering: YAML, JSON, CSV handling, Logging & Error Handling\n",
    "\n",
    "Projects:\n",
    "\n",
    "1. Stock Price Prediction using LSTM\n",
    "   - Built and trained an LSTM model using historical Apple stock data via yfinance\n",
    "   - Performed data preprocessing, scaling, and model evaluation\n",
    "   - Technologies: TensorFlow, Pandas, Matplotlib\n",
    "\n",
    "2. Resume Analyzer & Interview Bot\n",
    "   - Built a Streamlit app that evaluates resumes, gives ATS scores, and suggests improvements\n",
    "   - Includes features to generate interview questions and analyze job descriptions\n",
    "   - Integrated RAG-based Q&A with LLMs\n",
    "\n",
    "3. Customer Lifetime Value Prediction (CLTV)\n",
    "   - Performed RFM segmentation and applied BetaGeoFitter and GammaGamma models\n",
    "   - Developed marketing strategy recommendations for each customer cluster\n",
    "\n",
    "4. Hate Speech Detection (NLP)\n",
    "   - Created a dataset pipeline with MongoDB, Zip extraction, and preprocessing\n",
    "   - Built models to classify hate speech in tweets using logistic regression and NLP techniques\n",
    "\n",
    "Certifications:\n",
    "- AI For Everyone ‚Äì Coursera\n",
    "- Data Science & Machine Learning ‚Äì Kaggle Learn\n",
    "\n",
    "Achievements:\n",
    "- Completed over 10 real-world data science projects\n",
    "- Contributed to open-source ML templates using DVC and MLflow\n",
    "\n",
    "Languages:\n",
    "- English (Intermediate), Hindi (Native)\n",
    "\n",
    "Declaration:\n",
    "I hereby declare that the above information is true to the best of my knowledge.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc63c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ccba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(text):\n",
    "    \"\"\"Create a simpler vector store for skill analysis\"\"\"\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEYY)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Maximum size of each chunk\n",
    "    chunk_overlap=200,    # Overlap between chunks to maintain context\n",
    "    length_function=len ) # Function to measure chunk length\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def analyze_skills(ra_chain, skill):\n",
    "    \n",
    "    \"\"\"Analyze a single skill using the RAG chain and return skill, score, and cleaned reasoning.\"\"\"\n",
    "        \n",
    "        # Ask the chain for evaluation of the skill\n",
    "    query = f\"On a scale of 0-10, how clearly does the candidate mention proficiency in {skill}? Provide a numeric rating first, followed by reasoning\"\n",
    "    response = ra_chain.invoke({\"input\": query})\n",
    "\n",
    "        # Extract numeric score from the response\n",
    "    match = re.search(r'(\\d+)', response['answer'])\n",
    "    score = int(match.group(1)) if match else 0\n",
    "        # final_score = min(score, 10)\n",
    "\n",
    "        # Clean up the reasoning part\n",
    "    reasoning_raw = response['answer']\n",
    "    reasoning_lines = [line.strip() for line in reasoning_raw.split('\\n') if line.strip()]\n",
    "    raw_reasoning = \" \".join(reasoning_lines)\n",
    "\n",
    "        # Remove leading score and optional symbols\n",
    "    reasoning = re.sub(r'^\\d+\\s*[-.:]?\\s*', '', raw_reasoning)\n",
    "\n",
    "    return skill, min(score, 10), reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "def90a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke({\"query\": \"What skills does the resume show in MLOps?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be75290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the resume, Utkarsh Raj has experience with the following MLOps tools:\n",
      "\n",
      "*   DVC\n",
      "*   MLflow\n",
      "*   Apache Airflow\n",
      "*   Docker\n",
      "*   Git\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c21254",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6951997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "{'Python': 8, 'Java': 0, 'React': 0, 'PostgreSQL': 0, 'Cloud Computing (AWS/Azure/GCP)': 2, 'Leadership': 0, 'Project Management': 0, 'Machine Learning': 9}\n",
      "{'Python': 'The candidate lists Python under \"Programming Languages\" in the \"Skills\" section. While they don\\'t explicitly state their proficiency level (e.g., \"expert,\" \"proficient\"), its inclusion alongside SQL indicates a foundational skill. The listed projects further demonstrate practical application of Python. A higher rating could be warranted with an explicit self-assessment of proficiency.', 'Java': 'Java is not mentioned at all.', 'React': 'React is not mentioned in the document.', 'PostgreSQL': 'Reasoning: PostgreSQL is not mentioned anywhere in the provided text.', 'Cloud Computing (AWS/Azure/GCP)': 'The candidate only mentions Google Cloud Storage. There is no mention of AWS or Azure and their experience with Google Cloud Storage is not detailed.', 'Leadership': 'The candidate does not mention leadership skills in the provided text.', 'Project Management': 'The candidate does not explicitly mention proficiency in Project Management in the provided context.', 'Machine Learning': 'The candidate explicitly mentions \"Data Science & Machine Learning\" certification, \"hands-on experience in building machine learning models\", lists several ML-related tools and libraries under \"Skills,\" and describes multiple projects that clearly involve machine learning techniques. The objective also clearly states the candidate\\'s aspiration as a data scientist and experience with machine learning models.'}\n",
      "False\n",
      "Candidate evaluated based on explicit resume content using semantic similarity and clear numeric scoring.\n",
      "['Java', 'React', 'PostgreSQL', 'Cloud Computing (AWS/Azure/GCP)', 'Leadership', 'Project Management']\n",
      "['Python', 'Machine Learning']\n",
      "['Java', 'React', 'PostgreSQL', 'Cloud Computing (AWS/Azure/GCP)', 'Leadership', 'Project Management']\n"
     ]
    }
   ],
   "source": [
    "skill_scores = {}\n",
    "skill_reasoning = {}\n",
    "missing_skills = []\n",
    "total_score = 0\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input} \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "vectorstore = create_vector_store(resume_text)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "     \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "from langchain.chains import create_retrieval_chain\n",
    "ra_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "skills_analayze = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" # Example of a skill that might not be explicitly mentioned\n",
    "]\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(executor.map(lambda skill: analyze_skills(ra_chain, skill), skills))\n",
    "\n",
    "\n",
    "for skill, score, reasoning in results:\n",
    "\n",
    "    skill_scores[skill] = score\n",
    "    skill_reasoning[skill] = reasoning\n",
    "    total_score = total_score + score\n",
    "    if score <=5:\n",
    "          missing_skills.append(skill)\n",
    "    \n",
    "    # print(f\"Raw response for {skill}: {response['answer']}\")\n",
    "    \n",
    "overall_score = int((total_score / (10 *len(skills)))*100)\n",
    "\n",
    "selected = overall_score >= 50\n",
    "\n",
    "reasoning = \"Candidate evaluated based on explicit resume content using semantic similarity and clear numeric scoring.\"\n",
    "strengths = [skill for skill, score in skill_scores.items() if score >= 7]\n",
    "improvement_areas = missing_skills if not selected else []\n",
    "\n",
    "print(overall_score)\n",
    "print(skill_scores)\n",
    "print(skill_reasoning)\n",
    "print(selected)\n",
    "print(reasoning)\n",
    "print(missing_skills)\n",
    "print(strengths)\n",
    "print(improvement_areas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0896c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaknesses  = []\n",
    "improvement_suggestions = {}\n",
    "\n",
    "analysis_result = {\n",
    "    \"missing_skill\": [\"Mlops\", \"Devops\", 'GenerativeAI']\n",
    "}\n",
    "\n",
    "for skill in analysis_result.get('missing_skill', []):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze why the resume is weak in demonstrating proficiency in \"{skill}\".\n",
    "\n",
    "    For your analysis, consider:\n",
    "    1. What's missing from the resume regarding this skill?\n",
    "    2. How could it be improved with specific examples?\n",
    "    3. What specific action items would make this skill stand out?\n",
    "\n",
    "    Resume Content:\n",
    "    {resume_text[:30000]}\n",
    "\n",
    "    Provide your response in this JSON format:\n",
    "    {{\n",
    "        \"weakness\": \"A concise description of what's missing or problematic (1-2 sentences)\",\n",
    "        \"improvement_suggestions\": [\n",
    "            \"Specific suggestion 1\",\n",
    "            \"Specific suggestion 2\",\n",
    "            \"Specific suggestion 3\"\n",
    "        ],\n",
    "        \"example_addition\": \"A specific bullet point that could be added to showcase this skill\"\n",
    "    }}\n",
    "\n",
    "    Return only valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # ‚úÖ Extract string answer\n",
    "    raw_json = response.content\n",
    "\n",
    "    # ‚úÖ Remove backticks and 'json' label\n",
    "    cleaned_json = re.sub(r'^```json|```$', '', raw_json.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ Parse string into dictionary\n",
    "        weakness_data = json.loads(cleaned_json)\n",
    "\n",
    "        # ‚úÖ Store in desired format\n",
    "        weakness_detail = {\n",
    "            \"skill\": skill,\n",
    "            \"detail\": weakness_data.get(\"weakness\", \"No specific details provided.\"),\n",
    "            \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "            \"example\": weakness_data.get(\"example_addition\", \"\")\n",
    "        }\n",
    "\n",
    "        weaknesses.append(weakness_detail)\n",
    "        improvement_suggestions[skill] = {\n",
    "                    \"suggestions\": weakness_data.get(\"improvement_suggestions\", []),\n",
    "                    \"example\": weakness_data.get(\"example_addition\", \"\")}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed for skill {skill}: {e}\")\n",
    "        weaknesses.append({\n",
    "            \"skill\": skill,\n",
    "            \"detail\": raw_json[:200],  # fallback: first 200 characters\n",
    "            \n",
    "            \"example\": \"\"\n",
    "        })\n",
    "\n",
    "resume_weakness = weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "276d47fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Skill: Mlops\n",
      "‚ùå Weakness: The resume lists MLOps tools but lacks demonstrable application and impact within projects. There's no quantifiable evidence of how MLOps practices improved model deployment, monitoring, or overall project efficiency.\n",
      "üìå Example: - Implemented a CI/CD pipeline using DVC, MLflow, and Docker for the Stock Price Prediction project, resulting in a 40% reduction in model deployment time and automated model versioning.\n",
      "‚úÖ Suggestions:\n",
      "  - Quantify the impact of MLOps tools used in the projects. For example, improved model deployment speed, reduced training time, or enhanced model monitoring capabilities.\n",
      "  - Describe the specific MLOps workflows implemented (e.g., CI/CD pipeline for model deployment, automated model retraining process, version control for models and data).\n",
      "  - Focus on the end-to-end MLOps lifecycle, including data validation, model training, deployment, monitoring, and retraining.\n",
      "\n",
      "üîß Skill: Devops\n",
      "‚ùå Weakness: While the resume mentions DevOps tools like Docker, MLflow, and DVC, it lacks concrete examples demonstrating practical application within a DevOps context. It doesn't show how these tools were used to automate, streamline, or improve the development and deployment pipeline.\n",
      "üìå Example: Implemented a CI/CD pipeline using Jenkins and Docker to automate the deployment of the Resume Analyzer app, reducing deployment time by 40% and ensuring consistent environments across development, testing, and production.\n",
      "‚úÖ Suggestions:\n",
      "  - Quantify the impact of using DevOps tools. For example, specify reduced deployment time, improved efficiency, or enhanced scalability.\n",
      "  - Describe the infrastructure and automation aspects of the projects. Mention containerization, orchestration, CI/CD pipelines, and infrastructure-as-code.\n",
      "  - Elaborate on the role played in implementing DevOps practices, such as collaboration with developers and operations teams, monitoring, and continuous improvement.\n",
      "\n",
      "üîß Skill: GenerativeAI\n",
      "‚ùå Weakness: The resume lacks explicit and demonstrable evidence of Generative AI proficiency. While Project 2 mentions LLMs and RAG, it's vague and doesn't quantify the candidate's contributions or the specific generative AI models or techniques used.\n",
      "üìå Example: Developed a RAG-based question answering system using OpenAI's GPT-3, achieving a 20% improvement in question answering accuracy compared to traditional keyword-based search by fine-tuning the embedding model.\n",
      "‚úÖ Suggestions:\n",
      "  - Explicitly list specific Generative AI models or frameworks used, e.g., GPT-3, PaLM, Stable Diffusion, DALL-E 2, Langchain, Transformers library.\n",
      "  - Quantify the impact of any Generative AI projects. For example, by mentioning improvements in accuracy, efficiency, or user engagement.\n",
      "  - Detail specific tasks and contributions within the mentioned LLM project, particularly focusing on the Generative AI aspects. What part of the RAG pipeline did you work on? How did you fine-tune the LLM? What evaluation metrics were used?\n"
     ]
    }
   ],
   "source": [
    "for item in resume_weakness:\n",
    "    print(f\"\\nüîß Skill: {item['skill']}\")\n",
    "    print(f\"‚ùå Weakness: {item['detail']}\")\n",
    "    print(f\"üìå Example: {item['example']}\")\n",
    "    print(\"‚úÖ Suggestions:\")\n",
    "    for s in item['suggestions']:\n",
    "        print(f\"  - {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df07da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result = {'strengths':{'python', 'machine learning'}}\n",
    "extracted_skills = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"React\",\n",
    "    \"PostgreSQL\",\n",
    "    \"Cloud Computing (AWS/Azure/GCP)\",\n",
    "    \"Leadership\",\n",
    "    \"Project Management\",\n",
    "    \"Machine Learning\" \n",
    "]\n",
    "num_questions = 3\n",
    "difficulty = 'Medium'\n",
    "question_types = ['technical', 'Behavioural']\n",
    "context = f\"\"\"\n",
    "Resume Content:\n",
    "{resume_text[:2000]}...\n",
    "            \n",
    "Skills to focus on: {', '.join(extracted_skills)}\n",
    "            \n",
    "Strengths: {', '.join(analysis_result.get('strengths', []))}\n",
    "            \n",
    "Areas for improvement: {', '.join(missing_skills)}\n",
    "            \"\"\"\n",
    "            \n",
    "prompt = f\"\"\"\n",
    "Generate {num_questions} personalized {difficulty.lower()} level interview questions for this candidate \n",
    "based on their resume and skills. Include only the following question types: {', '.join(question_types)}.\n",
    "            \n",
    "For each question:\n",
    "1. Clearly label the question type\n",
    "2. Make the question specific to their background and skills\n",
    "3. For coding questions, include a clear problem statement\n",
    "            \n",
    "{context}\n",
    "            \n",
    "Format the response as a list of tuples with the question type and the question itself.\n",
    "Each tuple should be in the format: (\"Question Type\", \"Full Question Text\")\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "response =  llm.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c944f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 3 interview questions tailored for Utkarsh Raj, based on his resume and skills:\n",
      "\n",
      "```python\n",
      "[\n",
      "    (\"Technical\", \"In your Stock Price Prediction project, you used LSTM with TensorFlow. Could you describe a situation where a simple, less computationally expensive model like ARIMA might be preferred over LSTM, and explain the trade-offs involved in that decision, considering factors like data characteristics and prediction horizon?\"),\n",
      "    (\"Behavioural\", \"You've listed several projects on your resume, including the 'Resume Analyzer & Interview Bot'. Tell me about a time when you encountered a significant technical challenge while building this project. How did you approach problem-solving, what resources did you utilize, and what did you learn from the experience?\"),\n",
      "    (\"Technical\", \"In your Hate Speech Detection project, you mention creating a dataset pipeline. Let's say you need to productionize this pipeline to handle a continuous stream of tweets. Design a simple architecture using Apache Airflow to automate the data ingestion, preprocessing, model training, and deployment steps, considering scalability and fault tolerance. Please state any assumptions you make about the environment and data volume.\")\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "questions_text = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cae3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    (\"Technical\", \"In your Stock Price Prediction project, you used LSTM with TensorFlow. Could you describe a situation where a simple, less computationally expensive model like ARIMA might be preferred over LSTM, and explain the trade-offs involved in that decision, considering factors like data characteristics and prediction horizon?\"),\n",
      "    (\"Behavioural\", \"You've listed several projects on your resume, including the 'Resume Analyzer & Interview Bot'. Tell me about a time when you encountered a significant technical challenge while building this project. How did you approach problem-solving, what resources did you utilize, and what did you learn from the experience?\"),\n",
      "    (\"Technical\", \"In your Hate Speech Detection project, you mention creating a dataset pipeline. Let's say you need to productionize this pipeline to handle a continuous stream of tweets. Design a simple architecture using Apache Airflow to automate the data ingestion, preprocessing, model training, and deployment steps, considering scalability and fault tolerance. Please state any assumptions you make about the environment and data volume.\")\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "questions_text = response.content\n",
    "questions = []\n",
    "\n",
    "# Step 1: Remove any extra explanation text before the list\n",
    "match = re.search(r\"\\[\\s*\\(\", questions_text, re.DOTALL)\n",
    "if match:\n",
    "    start_index = match.start()\n",
    "    questions_text = questions_text[start_index:]\n",
    "\n",
    "# Step 2: Clean up Markdown or Python syntax\n",
    "questions_text = re.sub(r\"```(?:python)?|```\", \"\", questions_text).strip()\n",
    "print(questions_text)\n",
    "\n",
    "# Step 3: Safely evaluate the string into a Python list\n",
    "try:\n",
    "    questions_list = eval(questions_text)\n",
    "    questions = []\n",
    "    for question_type, question in questions_list:\n",
    "        for requested_type in question_types:\n",
    "            if requested_type.lower() in question_type.lower():\n",
    "                questions.append((question_type.strip(), question.strip()))\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Parsing failed: {e}\")\n",
    "    questions = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    improvements = {}\n",
    "    improvement_areas=[\"Skills Highlighting\", \"Project Description\", \"Achievements\"]\n",
    "    target_role=\"Data Scientist\"\n",
    "    for area in improvement_areas:\n",
    "        if area == \"Skills Highlighting\" and resume_weakness:\n",
    "            skill_improvements = {\n",
    "                        \"description\": \"Your resume needs to better highlight key skills that are important for the role.\",\n",
    "                        \"specific\": []\n",
    "                    }\n",
    "            \n",
    "\n",
    "\n",
    "            before_after_examples = {}\n",
    "            for weaknesses in resume_weakness:\n",
    "                skill_name = weaknesses.get(\"skill\", \"\")\n",
    "                if \"suggestions\" in weaknesses and weaknesses[\"suggestions\"]:\n",
    "                        for suggestion in weaknesses[\"suggestions\"]:\n",
    "                                skill_improvements[\"specific\"].append(f\"**{skill_name}**: {suggestion}\")\n",
    "\n",
    "            if 'example' in weaknesses and weaknesses['example']:\n",
    "                resume_chunks = resume_text.split('\\n\\n')\n",
    "                relevant_chunk = \"\"\n",
    "\n",
    "                for chunk in resume_chunks:\n",
    "                    if skill_name.lower() in chunk.lower() or \"experience\" in chunk.lower():\n",
    "                        relevant_chunk = chunk\n",
    "                        break\n",
    "                if relevant_chunk:\n",
    "                    before_after_examples = {\n",
    "                                    \"before\": relevant_chunk.strip(),\n",
    "                                    \"after\": relevant_chunk.strip() + \"\\n‚Ä¢ \" + weaknesses[\"example\"]\n",
    "                                }\n",
    "        if before_after_examples:\n",
    "            skill_improvements[\"before_after\"] = before_after_examples\n",
    "        improvements[\"Skills Highlighting\"] = skill_improvements\n",
    "            \n",
    "             \n",
    "    remaining_areas = [area for area in improvement_areas if area not in improvements]\n",
    "    if remaining_areas:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "            \n",
    "        weaknesses_text = \"\"\n",
    "        if resume_weakness:\n",
    "            weaknesses_text  = \"Resume Weaknesses:\\n\"\n",
    "        for i, weakness in enumerate(resume_weakness):\n",
    "            weaknesses_text += f\"{i+1}. {weakness['skill']}: {weakness['detail']}\\n\"\n",
    "    \n",
    "            if \"suggestions\" in weakness:\n",
    "                for j, sugg in enumerate(weakness[\"suggestions\"]):\n",
    "                    weaknesses_text += f\"   - {sugg}\\n\"\n",
    "\n",
    "    context = f\"\"\"\n",
    "                Resume Content:\n",
    "                {resume_text}\n",
    "                \n",
    "                Skills to focus on: {', '.join(extracted_skills)}\n",
    "                \n",
    "                Strengths: {', '.join(analysis_result.get('strengths', []))}\n",
    "                \n",
    "                Areas for improvement: {', '.join(analysis_result.get('missing_skills', []))}\n",
    "                \n",
    "                {weaknesses_text}\n",
    "                \n",
    "                Target role: {target_role if target_role else \"Not specified\"}\n",
    "                \"\"\"\n",
    "                \n",
    "    prompt = f\"\"\"\n",
    "                Provide detailed suggestions to improve this resume in the following areas: {', '.join(remaining_areas)}.\n",
    "                \n",
    "                {context}\n",
    "                \n",
    "                For each improvement area, provide:\n",
    "                1. A general description of what needs improvement\n",
    "                2. 3-5 specific actionable suggestions\n",
    "                3. Where relevant, provide a before/after example\n",
    "                \n",
    "                Format the response as a JSON object with improvement areas as keys, each containing:\n",
    "                - \"description\": general description\n",
    "                - \"specific\": list of specific suggestions\n",
    "                - \"before_after\": (where applicable) a dict with \"before\" and \"after\" examples\n",
    "                \n",
    "                Only include the requested improvement areas that aren't already covered.\n",
    "                Focus particularly on addressing the resume weaknesses identified.\n",
    "                \"\"\"\n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    # try to parse json response\n",
    "    ai_improvements = {}\n",
    "    json_match = re.search(r'```(?:json)?\\s*([\\s\\S]+?)\\s*```', response.content)\n",
    "    if json_match:\n",
    "        try:\n",
    "            ai_improvements = json.loads(json_match.group(1))\n",
    "            # merge with existing imoprovemtns\n",
    "            improvements.update(ai_improvements)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "          \n",
    "            \n",
    "\n",
    "\n",
    "except Exception as e: \n",
    "    pass\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4de7ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = response.content\n",
    "json_match = re.search(r'```(?:json)?\\s*([\\s\\S]+?)\\s*```', response.content)\n",
    "ai_immmpo = {}\n",
    "impo = {}\n",
    "ai_immmpo = json.loads(json_match.group(1))\n",
    "impo.update(ai_immmpo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "741b5c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Your resume needs to better highlight key skills that are important for the role.', 'specific': ['**Mlops**: Quantify the impact of MLOps tools used in the projects. For example, improved model deployment speed, reduced training time, or enhanced model monitoring capabilities.', '**Mlops**: Describe the specific MLOps workflows implemented (e.g., CI/CD pipeline for model deployment, automated model retraining process, version control for models and data).', '**Mlops**: Focus on the end-to-end MLOps lifecycle, including data validation, model training, deployment, monitoring, and retraining.', '**Devops**: Quantify the impact of using DevOps tools. For example, specify reduced deployment time, improved efficiency, or enhanced scalability.', '**Devops**: Describe the infrastructure and automation aspects of the projects. Mention containerization, orchestration, CI/CD pipelines, and infrastructure-as-code.', '**Devops**: Elaborate on the role played in implementing DevOps practices, such as collaboration with developers and operations teams, monitoring, and continuous improvement.', '**GenerativeAI**: Explicitly list specific Generative AI models or frameworks used, e.g., GPT-3, PaLM, Stable Diffusion, DALL-E 2, Langchain, Transformers library.', '**GenerativeAI**: Quantify the impact of any Generative AI projects. For example, by mentioning improvements in accuracy, efficiency, or user engagement.', '**GenerativeAI**: Detail specific tasks and contributions within the mentioned LLM project, particularly focusing on the Generative AI aspects. What part of the RAG pipeline did you work on? How did you fine-tune the LLM? What evaluation metrics were used?'], 'before_after': {'before': 'Objective:\\nAspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.', 'after': \"Objective:\\nAspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.\\n‚Ä¢ Developed a RAG-based question answering system using OpenAI's GPT-3, achieving a 20% improvement in question answering accuracy compared to traditional keyword-based search by fine-tuning the embedding model.\"}}\n"
     ]
    }
   ],
   "source": [
    "for area in improvement_areas:\n",
    "    if area not in improvements:\n",
    "        improvements[area] = {\n",
    "                        \"description\": f\"Improvements needed in {area}\",\n",
    "                        \"specific\": [\"Review and enhance this section\"]\n",
    "                    }\n",
    "print(improvements['Skills Highlighting'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "508fd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Area: Skills Highlighting\n",
      "üìù Description: Your resume needs to better highlight key skills that are important for the role.\n",
      "  üîπ **Mlops**: Quantify the impact of MLOps tools used in the projects. For example, improved model deployment speed, reduced training time, or enhanced model monitoring capabilities.\n",
      "  üîπ **Mlops**: Describe the specific MLOps workflows implemented (e.g., CI/CD pipeline for model deployment, automated model retraining process, version control for models and data).\n",
      "  üîπ **Mlops**: Focus on the end-to-end MLOps lifecycle, including data validation, model training, deployment, monitoring, and retraining.\n",
      "  üîπ **Devops**: Quantify the impact of using DevOps tools. For example, specify reduced deployment time, improved efficiency, or enhanced scalability.\n",
      "  üîπ **Devops**: Describe the infrastructure and automation aspects of the projects. Mention containerization, orchestration, CI/CD pipelines, and infrastructure-as-code.\n",
      "  üîπ **Devops**: Elaborate on the role played in implementing DevOps practices, such as collaboration with developers and operations teams, monitoring, and continuous improvement.\n",
      "  üîπ **GenerativeAI**: Explicitly list specific Generative AI models or frameworks used, e.g., GPT-3, PaLM, Stable Diffusion, DALL-E 2, Langchain, Transformers library.\n",
      "  üîπ **GenerativeAI**: Quantify the impact of any Generative AI projects. For example, by mentioning improvements in accuracy, efficiency, or user engagement.\n",
      "  üîπ **GenerativeAI**: Detail specific tasks and contributions within the mentioned LLM project, particularly focusing on the Generative AI aspects. What part of the RAG pipeline did you work on? How did you fine-tune the LLM? What evaluation metrics were used?\n",
      "\n",
      "üßæ Before:\n",
      " Objective:\n",
      "Aspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.\n",
      "\n",
      "‚úÖ After:\n",
      " Objective:\n",
      "Aspiring Data Scientist with hands-on experience in building machine learning models, performing data analysis, and implementing MLOps tools. Seeking to leverage my skills to solve real-world business problems and deliver data-driven solutions.\n",
      "‚Ä¢ Developed a RAG-based question answering system using OpenAI's GPT-3, achieving a 20% improvement in question answering accuracy compared to traditional keyword-based search by fine-tuning the embedding model.\n",
      "\n",
      "üìò Area: Project Description\n",
      "üìù Description: Improvements needed in Project Description\n",
      "  üîπ Review and enhance this section\n",
      "\n",
      "üìò Area: Achievements\n",
      "üìù Description: Improvements needed in Achievements\n",
      "  üîπ Review and enhance this section\n"
     ]
    }
   ],
   "source": [
    "for area, content in improvements.items():\n",
    "    print(f\"\\nüìò Area: {area}\")\n",
    "    print(f\"üìù Description: {content['description']}\")\n",
    "    for item in content.get(\"specific\", []):\n",
    "        print(f\"  üîπ {item}\")\n",
    "    if \"before_after\" in content:\n",
    "        print(\"\\nüßæ Before:\\n\", content[\"before_after\"].get(\"before\", \"\"))\n",
    "        print(\"\\n‚úÖ After:\\n\", content[\"before_after\"].get(\"after\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_role=\"Data Scientist\"\n",
    "highlight_skills=\"Python, Machine Learning, SQL\"\n",
    "skills_to_highlight = []\n",
    "\n",
    "if len(highlight_skills)>100:\n",
    "    jd_text  = highlight_skills\n",
    "    try:\n",
    "        parsed_skills = extract_skills_jd(highlight_skills)\n",
    "        if parsed_skills:\n",
    "            skills_to_highlight = parsed_skills\n",
    "        else:\n",
    "            skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "    except:\n",
    "        skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "else:\n",
    "    skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Title: Data Scientist\n",
      "Location: Remote / Bangalore, India\n",
      "Job Type: Full-time\n",
      "\n",
      "About the Role:\n",
      "We are seeking a Data Scientist who is passionate about using data to solve real-world problems and drive strategic decisions. You'll work closely with business, product, and engineering teams to uncover insights, build predictive models, and design experiments that impact millions of users.\n",
      "\n",
      "Key Responsibilities:\n",
      "- Analyze structured and unstructured data from multiple sources to extract meaningful insights.\n",
      "- Build machine learning models for prediction, classification, segmentation, and recommendation.\n",
      "- Design A/B tests and evaluate the performance of models and features.\n",
      "- Communicate findings clearly to stakeholders using dashboards, reports, and visualizations.\n",
      "- Collaborate with data engineers and software developers to deploy scalable data solutions.\n",
      "- Monitor model performance and perform periodic model retraining.\n",
      "\n",
      "Required Skills & Qualifications:\n",
      "- Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or related field.\n",
      "- 2+ years of experience in data science or a similar role.\n",
      "- Strong knowledge of Python, SQL, and machine learning libraries like scikit-learn, TensorFlow, or PyTorch.\n",
      "- Hands-on experience with data analysis and visualization tools such as Pandas, Matplotlib, Seaborn, or Tableau.\n",
      "- Understanding of statistical modeling, hypothesis testing, and experimental design.\n",
      "- Experience working with large datasets and cloud platforms (AWS, GCP, or Azure).\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a86ed79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_improved_resume(target_role, highlight_skills, jd_text):\n",
    "    \"\"\"Generate an improved version of the resume optimized for the job description\"\"\"\n",
    "    if not resume_text:\n",
    "        return \"Please upload and analyze a resume first.\"\n",
    "\n",
    "    try:\n",
    "        # Parse highlight skills if provided\n",
    "        skills_to_highlight = []\n",
    "        if highlight_skills:\n",
    "            if len(highlight_skills) > 100:\n",
    "                jd_text = highlight_skills\n",
    "                try:\n",
    "                    parsed_skills = extract_skills_jd(highlight_skills)\n",
    "                    if parsed_skills:\n",
    "                        skills_to_highlight = parsed_skills\n",
    "                    else:\n",
    "                        skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "                except:\n",
    "                        skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "        else:\n",
    "            skills_to_highlight = [s.strip() for s in highlight_skills.split(\",\") if s.strip()]\n",
    "\n",
    "        if not skills_to_highlight and analysis_result:\n",
    "            skills_to_highlight = analysis_result.get('missing_skills', [])\n",
    "            skills_to_highlight.extend([\n",
    "                skill for skill in analysis_result.get('strengths', [])\n",
    "                if skill not in skills_to_highlight\n",
    "                ])\n",
    "            if extracted_skills:\n",
    "                    skills_to_highlight.extend([\n",
    "                        skill for skill in extracted_skills\n",
    "                        if skill not in skills_to_highlight\n",
    "                    ])\n",
    "\n",
    "        weakness_context = \"\"\n",
    "        improvement_examples = \"\"\n",
    "        if resume_weakness:\n",
    "            weakness_context = \"Address these specific weaknesses:\\n\"\n",
    "            for weakness in resume_weakness:\n",
    "                skill_name = weakness.get('skill', '')\n",
    "                weakness_context += f\"- {skill_name}: {weakness.get('detail', '')}\\n\"\n",
    "                if 'suggestions' in weakness and weakness['suggestions']:\n",
    "                    weakness_context += \"  Suggested improvements:\\n\"\n",
    "                    for suggestion in weakness['suggestions']:\n",
    "                        weakness_context += f\"  * {suggestion}\\n\"\n",
    "                if 'example' in weakness and weakness['example']:\n",
    "                    improvement_examples += f\"For {skill_name}: {weakness['example']}\\n\\n\"\n",
    "\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEYY)\n",
    "\n",
    "        jd_context = \"\"\n",
    "        if jd_text:\n",
    "            jd_context = f\"Job Description:\\n{jd_text}\\n\\n\"\n",
    "        elif target_role:\n",
    "            jd_context = f\"Target Role: {target_role}\\n\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            Rewrite and improve this resume to make it highly optimized for the target job.\n",
    "\n",
    "            {jd_context}\n",
    "            Original Resume:\n",
    "            {resume_text}\n",
    "\n",
    "            Skills to highlight (in order of priority): {', '.join(skills_to_highlight)}\n",
    "\n",
    "            {weakness_context}\n",
    "\n",
    "            Here are specific examples of content to add:\n",
    "            {improvement_examples}\n",
    "\n",
    "            Please improve the resume by:\n",
    "            1. Adding strong, quantifiable achievements\n",
    "            2. Highlighting the specified skills strategically for ATS scanning\n",
    "            3. Addressing all the weakness areas identified with the specific suggestions provided\n",
    "            4. Incorporating the example improvements provided above\n",
    "            5. Structuring information in a clear, professional format\n",
    "            6. Using industry-standard terminology\n",
    "            7. Ensuring all relevant experience is properly emphasized\n",
    "            8. Adding measurable outcomes and achievements\n",
    "\n",
    "            Return only the improved resume text without any additional explanations.\n",
    "            Format the resume in a modern, clean style with clear section headings.\n",
    "            \"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        improved_resume = response.content.strip()\n",
    "\n",
    "        # with tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8') as tmp:\n",
    "        #     tmp.write(improved_resume)\n",
    "        #     improved_resume_path = tmp.name\n",
    "\n",
    "        return improved_resume\n",
    "    except Exception as e:\n",
    "            print(f\"Error generating improved resume: {e}\")\n",
    "            return \"Error generating improved resume. Please try again.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c4cb44eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Utkarsh Raj**\n",
      "Email: utkarsh@example.com | Phone: +91-9876543210 | Location: Bangalore, India (Remote)\n",
      "LinkedIn: www.linkedin.com/in/utkarsh9911 | GitHub: github.com/utkarshraj99\n",
      "\n",
      "**Summary**\n",
      "\n",
      "Data Scientist with 2+ years of experience leveraging machine learning, statistical analysis, and cloud technologies to drive data-informed decisions. Proven ability to build and deploy predictive models, design and analyze A/B tests, and communicate complex findings to stakeholders. Proficient in Python, SQL, and leading machine learning frameworks. Passionate about applying MLOps and DevOps principles to improve model performance and deployment efficiency.\n",
      "\n",
      "**Skills**\n",
      "\n",
      "*   **Programming Languages:** Python, SQL\n",
      "*   **Machine Learning:** Scikit-learn, TensorFlow, PyTorch, Regression, Classification, Clustering, Time Series Analysis, NLP\n",
      "*   **Data Analysis & Visualization:** Pandas, NumPy, Matplotlib, Seaborn, Tableau\n",
      "*   **Cloud Computing:** Google Cloud Platform (GCP), Google Cloud Storage\n",
      "*   **MLOps:** DVC, MLflow, Docker, Apache Airflow, CI/CD Pipelines, Model Versioning, Automated Retraining\n",
      "*   **DevOps:** Docker, Jenkins, CI/CD, Containerization\n",
      "*   **Generative AI:** OpenAI GPT-3, RAG, LLMs, Fine-tuning\n",
      "*   **Data Engineering:** YAML, JSON, CSV, Data Pipelines, Data Preprocessing\n",
      "*   **Version Control:** Git, GitHub\n",
      "*   **Statistical Modeling:** Hypothesis Testing, Experimental Design, A/B Testing\n",
      "\n",
      "**Projects**\n",
      "\n",
      "1.  **Stock Price Prediction using LSTM (MLOps Focus)**\n",
      "    *   Developed an LSTM model using TensorFlow and historical stock data (yfinance) for predicting Apple stock prices.\n",
      "    *   Implemented a CI/CD pipeline using DVC, MLflow, and Docker for automated model deployment and versioning, resulting in a **40% reduction in model deployment time**.\n",
      "    *   Utilized MLflow for experiment tracking and model registry, enabling efficient model comparison and selection.\n",
      "    *   Technologies: TensorFlow, Pandas, Matplotlib, DVC, MLflow, Docker\n",
      "\n",
      "2.  **Resume Analyzer & Interview Bot (Generative AI & DevOps Focus)**\n",
      "    *   Built a Streamlit application featuring resume evaluation, ATS scoring, interview question generation, and job description analysis.\n",
      "    *   Developed a RAG-based question answering system using OpenAI's GPT-3, achieving a **20% improvement in question answering accuracy** compared to traditional keyword-based search by fine-tuning the embedding model.\n",
      "    *   Implemented a CI/CD pipeline using Jenkins and Docker to automate the deployment of the Resume Analyzer app, **reducing deployment time by 40%** and ensuring consistent environments across development, testing, and production.\n",
      "    *   Technologies: Streamlit, OpenAI GPT-3, Langchain, RAG, Jenkins, Docker\n",
      "\n",
      "3.  **Customer Lifetime Value Prediction (CLTV)**\n",
      "    *   Performed RFM segmentation to identify key customer segments and predict Customer Lifetime Value (CLTV).\n",
      "    *   Applied BetaGeoFitter and GammaGamma models to forecast future customer spending behavior.\n",
      "    *   Developed targeted marketing strategy recommendations based on CLTV predictions to **increase customer retention by 15%**.\n",
      "    *   Technologies: Pandas, Scikit-learn, Lifetimes\n",
      "\n",
      "4.  **Hate Speech Detection (NLP)**\n",
      "    *   Designed and implemented a data pipeline to extract, process, and clean tweet data from MongoDB and Zip archives.\n",
      "    *   Developed machine learning models, including logistic regression, to classify hate speech in tweets with **90% accuracy**.\n",
      "    *   Improved model performance by implementing advanced NLP techniques such as TF-IDF vectorization and word embeddings.\n",
      "    *   Technologies: Python, NLTK, SpaCy, MongoDB, Scikit-learn\n",
      "\n",
      "**Education**\n",
      "\n",
      "*   **Bachelor of Science in Computer Science** (2021 ‚Äì 2025)\n",
      "    Maharshi Dayanand University, Rohtak, Haryana\n",
      "\n",
      "**Certifications**\n",
      "\n",
      "*   AI For Everyone ‚Äì Coursera\n",
      "*   Data Science & Machine Learning ‚Äì Kaggle Learn\n",
      "\n",
      "**Languages**\n",
      "\n",
      "*   English (Intermediate)\n",
      "*   Hindi (Native)\n"
     ]
    }
   ],
   "source": [
    "target_role=\"Data Scientist\"\n",
    "highlight_skills=\"Python, Machine Learning, SQL\"\n",
    "\n",
    "print(get_improved_resume(target_role, highlight_skills, jd_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e642957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81d34ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rakesh\n",
      "1234\n"
     ]
    }
   ],
   "source": [
    "class person:\n",
    "    def __init__(self, name: str, course:str, address:int):\n",
    "        self.name = name\n",
    "\n",
    "        self.__course = course\n",
    "        self._address = address\n",
    "        # self.__address = address\n",
    "\n",
    "    def getinfo(self):\n",
    "        return self.name, self._address, self.__course\n",
    "\n",
    "ab = person('rakesh', 'btech', 1234)\n",
    "ans = ab\n",
    "print(ans.name)\n",
    "# for i in ans:\n",
    "#     print(i)\n",
    "print(ab._address)\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e41cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitbull\n",
      "wild\n",
      "brown\n",
      "woof\n"
     ]
    }
   ],
   "source": [
    "class dog:\n",
    "    def __init__(self, breed, color):\n",
    "        self.breed = breed\n",
    "        self.color = color\n",
    "    def sound(self):\n",
    "        return 'woof'\n",
    "\n",
    "class anotherbreed(dog):\n",
    "    def __init__(self, name,breed,color):\n",
    "        super().__init__(breed,color)\n",
    "        self.name = name\n",
    "        self.sound()\n",
    "    def getinfo(self):\n",
    "        return self.name, self.breed, self.color, self.sound()\n",
    "\n",
    "ab = anotherbreed('pitbull', 'wild', 'brown')    \n",
    "for ans in ab.getinfo():\n",
    "    print(ans)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f4b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
